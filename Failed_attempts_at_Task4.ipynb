{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyC7EvplSZfQ",
        "outputId": "6a1df19c-c3b8-4f57-a639-287a7ba21510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.0-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.0 huggingface-hub-0.11.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (4.64.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.8.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (3.19.6)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2.23.0)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0) (2022.6.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=abefe0c01a8cbdec99dbb7b58d2fa29c53c1ee382ba73508e3e387dbcf7655ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.9.2 transformers-3.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2022.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.13.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "# !pip install transformers\n",
        "!pip install transformers==3.4.0\n",
        "#I did this because I was getting some error (don't remember, it's been a week since I ran these) and stackoverflow told me that the error was\n",
        "#because transformers are not backwards compatible and doing this did fix that error\n",
        "!pip install evaluate\n",
        "#NOTE: This notebook is messy because I went pretty deep in the rabbit hole of debugging but I've tried to explain what was going on in my head at the time\n",
        "#But, none of the stuff here actually works, hence the name of this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZqYEmJ9OIah"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "#For Task 4 on the Children's Book Test dataset, the authors chose NE and CN only\n",
        "datasetCBTNE = load_dataset(\"cbt\", \"NE\")\n",
        "datasetCBTCN = load_dataset(\"cbt\", \"CN\")\n",
        "# # you can use any of the following config names as a second argument:\n",
        "# \"CN\", \"NE\", \"P\", \"V\", \n",
        "# \"raw\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPdGtS-YS343"
      },
      "outputs": [],
      "source": [
        "# print(\"CBT\", datasetCBTNE)\n",
        "# print(\"CBT\", datasetCBTCN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "1aa84aab6c3b4dce86c3a7fcb428b9fc",
            "12516509555e4681998ee83f6ee5811f",
            "036b85d1eb954a5a9c430eb5a9a0013a",
            "f35f7691a3ac4216bdbe4a6260878ed8",
            "96255bd4ae914808ac5dbac9baf28c09",
            "a111a92757414b2ca5d3c4f4a557b8d7",
            "e667576be66e44cca4261b78cd26ab6d",
            "393ab475c9f64be4ad49ec3614163277",
            "6af7565d842b4680ab1d68ad381faed0",
            "c4ee0b822dfb4bd09708c65714678140",
            "88503b6036d040bf93c617f9aafc1105"
          ]
        },
        "id": "z8Rk86yrTN-L",
        "outputId": "312b0f6d-8bf1-4a72-b200-b4b5fbc4f72b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1aa84aab6c3b4dce86c3a7fcb428b9fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentences', 'question', 'answer', 'options'],\n",
            "        num_rows: 92411\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentences', 'question', 'answer', 'options'],\n",
            "        num_rows: 16308\n",
            "    })\n",
            "}) Dataset({\n",
            "    features: ['sentences', 'question', 'answer', 'options'],\n",
            "    num_rows: 2500\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset, load_metric, ClassLabel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import os\n",
        "import json\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "\tlogits,labels = eval_pred\n",
        "\tpredictions = np.argmax(logits, axis=-1)\n",
        "\tresult = metric.compute(predictions=predictions, references=labels)\n",
        "\treturn result\n",
        "\n",
        "# CBT sentence level auto QA - \n",
        "datasetCBTNE_train = datasetCBTNE[\"train\"].train_test_split(test_size=0.15)\n",
        "datasetCBTNE_test = datasetCBTNE[\"test\"]\n",
        "# datasetCBTCN_train = datasetCBTCN[\"train\"]\n",
        "# datasetCBTCN_test = datasetCBTCN[\"test\"]\n",
        "print(datasetCBTNE_train, datasetCBTNE_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAJEcRTGXUwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d601c4-584f-4b43-f528-b94d56a7d49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tokenizer...\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentences', 'question', 'labels', 'options'],\n",
            "        num_rows: 92411\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentences', 'question', 'labels', 'options'],\n",
            "        num_rows: 16308\n",
            "    })\n",
            "}) Dataset({\n",
            "    features: ['sentences', 'question', 'labels', 'options'],\n",
            "    num_rows: 2500\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(\"building tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "#I tried to make it so that the dataset would have text and label columns so that DistilBERT doesn't get confused and knows what to do (classification)\n",
        "#But it did not work\n",
        "\n",
        "# datasetCBTNE_train = datasetCBTNE_train.rename_column('answer', 'labels')\n",
        "# datasetCBTNE_test = datasetCBTNE_test.rename_column('answer', 'labels')\n",
        "# print(datasetCBTNE_train, datasetCBTNE_test)\n",
        "# datasetCBTNE_train = datasetCBTNE_train.rename_column('question', 'text')\n",
        "# datasetCBTNE_test = datasetCBTNE_test.rename_column('question', 'text')\n",
        "def tokenize_function(examples):\n",
        "\ttoken = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\treturn token\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized_datasetCBTNE_train = datasetCBTNE_train.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasetCBTNE_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "5e5faec1a0eb4a81a26e8216e831083a",
            "e3e1cba538a04028a13e87d8e4f59f05",
            "74b8a34fc19c450b83fd0f04bab8deee",
            "797c34fd501a4a83ab0d75c9b048a57e",
            "f78e5f226b854014902f6d2dbadcb42d",
            "68e2454a032f4fe184f389c4f2526bff",
            "05c244827e8f444593874fd546e03fef",
            "6b04a0208011402bae3d2ec18a6e9103",
            "9118d819f12142a18474e85b95af5cdd",
            "a78fedc7cde04996a8031f499ad4487c",
            "ae465cc8523c44a783ac4759e1213c38",
            "dd88d466f7644bf89f40cde073e1d449",
            "7a94fea8dd6948a4928df564620c2e93",
            "62345609f82749c387d2ccf0d87116ea",
            "75e5a11489eb448c9e93f8d9fd25ba57",
            "d2af333e809d49a89cbeb33253d8ea6f",
            "b2f45818e6574246b8151af26cb31a8f",
            "d3c4ee213fce482c906ebd08b216e20a",
            "f7aac9711f214ff4be198b60b2e0ed26",
            "5df93393edff4e6097ddb09c9f0b8e74",
            "284dffbf9b6142be8d12de51fae83ff9",
            "e3dc5acfa0d24a3e8f723534ac56b159"
          ]
        },
        "id": "mzMHAAkpGni7",
        "outputId": "c433846f-52e1-481d-e9c9-18862a15f832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/93 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e5faec1a0eb4a81a26e8216e831083a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd88d466f7644bf89f40cde073e1d449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentences', 'text', 'labels', 'options', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 92411\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentences', 'text', 'labels', 'options', 'input_ids', 'attention_mask'],\n",
            "        num_rows: 16308\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for converting string labels to int and vice-versa\n",
        "\n",
        "label_names = datasetCBTNE_train['train'].unique('labels')\n",
        "label_dict = {}\n",
        "for i in range(len(label_names)):\n",
        "  label_dict[i] = label_names[i]\n",
        "\n",
        "print(label_dict)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\")\n",
        "id2label = {k:l for k, l in enumerate(label_names)}\n",
        "label2id = {l:k for k, l in enumerate(label_names)}\n",
        "\n",
        "#Was getting an error that inputids and attentionmask is missing so added this to fix that but did not need it later on\n",
        "\n",
        "# columns_to_return = ['input_ids', 'labels', 'attention_mask']\n",
        "# tokenized_datasetCBTNE_train['train'].set_format(type='torch', columns=columns_to_return)\n",
        "# tokenized_datasetCBTNE_train['test'].set_format(type='torch', columns=columns_to_return)\n",
        "# print(tokenized_datasetCBTNE_train['train'], tokenized_datasetCBTNE_train['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBqKIyTUG97Y",
        "outputId": "818cafed-17f0-4743-fb4d-425ea87258e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/cbt/NE/1.1.0/73e4c9316b0d86a7addd7f80183fb971a6161fa2f8b746da034e205b7e16f78d/cache-96b9c7cc52201439.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Eisenkopf', 1: 'Katherine', 2: 'Alec', 3: 'Chipmunk', 4: 'Saxons', 5: 'Mollie', 6: 'Brown', 7: 'Unicorn', 8: 'Peter', 9: 'Joey', 10: 'John', 11: 'Pye', 12: 'Jem', 13: 'Anne', 14: 'Alice', 15: 'Jo', 16: 'Mouse', 17: 'Blythe', 18: 'World', 19: 'Lady', 20: 'morning', 21: 'evening', 22: 'Dick', 23: 'Thorny', 24: 'Rose-Leaf', 25: 'Cinderella', 26: 'Barr', 27: 'Danby', 28: 'Tom', 29: 'Meg', 30: 'Hans', 31: 'Nature', 32: 'Makoma', 33: 'Hannah', 34: 'Annie', 35: 'Possum', 36: 'Gilbert', 37: 'Charlotta', 38: 'Margaret', 39: 'Meredith', 40: 'peris', 41: 'godmother', 42: 'days', 43: 'Rabbit', 44: 'Queen', 45: 'Forest', 46: 'Bagheera', 47: 'fire', 48: 'Minot', 49: 'Hester', 50: 'Helen', 51: 'Lavinia', 52: 'Rusty', 53: 'Bennett', 54: 'Douglas', 55: 'Diana', 56: 'Costan', 57: 'Shirley', 58: 'Germany', 59: 'Alan', 60: 'Melissa', 61: 'Ted', 62: 'Ruth', 63: 'Boxer', 64: 'Jims', 65: 'swineherd', 66: 'Ingleside', 67: 'Paul', 68: 'Sally', 69: 'Fox', 70: 'Campbell', 71: 'Aunty', 72: 'grown-ups', 73: 'Patty', 74: 'Endicott', 75: 'Jack', 76: 'right', 77: 'Topsy', 78: 'Marcella', 79: 'Gus', 80: 'Fisherman', 81: 'day', 82: 'Michael', 83: 'first', 84: 'fall', 85: 'Bell', 86: 'Franz', 87: 'Ho', 88: 'Thistle', 89: 'Meadows', 90: 'Blacky', 91: 'Susan', 92: 'Mahbub', 93: 'Marilla', 94: 'Trout', 95: 'Jackal', 96: 'pudding', 97: 'Muskrat', 98: 'Dan', 99: 'goblins', 100: 'Missy', 101: 'Whitefoot', 102: 'Fraser', 103: 'Kate', 104: 'Eva', 105: 'night', 106: 'Stan', 107: 'Isabel', 108: 'Kisa', 109: 'Bhaer', 110: 'Jane', 111: 'Ciccu', 112: 'Louisa', 113: 'Bernez', 114: 'Joyce', 115: 'henhouse', 116: 'Wolf', 117: 'Una', 118: 'Mowgli', 119: 'Blefuscu', 120: 'Rocket', 121: 'Cuthbert', 122: 'Donald', 123: 'Smee', 124: 'Lightfoot', 125: 'Wallace', 126: 'Laurie', 127: 'Frog', 128: 'Tegumai', 129: 'giantess', 130: 'River', 131: 'Blair', 132: 'Murray', 133: 'Beth', 134: 'clamour', 135: 'Circe', 136: 'Newbridge', 137: 'Carl', 138: 'Matcham', 139: 'Rosemary', 140: 'hookah', 141: 'Darling', 142: 'Ben', 143: 'Lita', 144: 'Crocodile', 145: 'Spartan', 146: 'Charlotte', 147: 'Rose', 148: 'Bowser', 149: 'Reddy', 150: 'Mother', 151: 'Peggy', 152: 'Kilmeny', 153: 'Jerry', 154: 'King', 155: 'Unc', 156: 'Stephen', 157: 'Poppy', 158: 'Skunk', 159: 'Janet', 160: 'Buzzard', 161: 'Martin', 162: 'Grimes', 163: 'Bab', 164: 'Dapplegrim', 165: 'Sultan', 166: \"O'Brien\", 167: 'Saul', 168: 'Ned', 169: 'puma', 170: 'year', 171: 'Daniel', 172: 'Cat', 173: 'Father', 174: 'Virgilius', 175: 'Tommy', 176: 'war', 177: 'Gunnar', 178: 'snuff-box', 179: 'fence-post', 180: 'Sunbeams', 181: 'Lasse', 182: 'Don', 183: 'Labakan', 184: 'Benjamin', 185: 'afternoon', 186: 'posset', 187: 'Mink', 188: 'Tha', 189: 'Rachel', 190: 'Rob', 191: 'Lynde', 192: 'Billy', 193: 'squirrels', 194: 'Nancy', 195: 'Bertha', 196: 'Gunga', 197: 'daughter-in-law', 198: 'Joscelyn', 199: 'Denise', 200: 'crusts', 201: 'vizier', 202: 'afternoons', 203: 'David', 204: 'Holland', 205: 'Celia', 206: 'Cornelia', 207: 'dagger', 208: 'quilt', 209: 'Coyote', 210: 'reindeer', 211: 'Gators', 212: 'Laurence', 213: 'Ophelia', 214: 'Guilbert', 215: 'Betty', 216: 'Olivia', 217: 'Lombardies', 218: 'Bear', 219: 'life-book', 220: 'Dumpty', 221: 'Nunda', 222: 'before', 223: 'Pantouflia', 224: 'Millicent', 225: 'Aquila', 226: 'Hugh', 227: 'left', 228: 'Catesby', 229: 'Susanna', 230: 'Lucinda', 231: 'Dominicus', 232: 'horse-dealer', 233: 'Glen', 234: 'Isaac', 235: 'Avery', 236: 'Chatterer', 237: 'Daisy', 238: 'Charles', 239: 'Leslie', 240: 'Frank', 241: 'Squirrel', 242: 'jackal', 243: 'Nat', 244: 'whale', 245: 'Robinson', 246: 'dressmaker', 247: 'Magician', 248: 'spruces', 249: 'ostriches', 250: 'Gryphon', 251: 'Dolly', 252: 'Sahib', 253: 'Caw', 254: 'Pandora', 255: 'Josie', 256: 'Trouts', 257: 'drogha', 258: 'Mattie', 259: 'Bess', 260: 'Captain', 261: 'Adolphus', 262: 'Herbert', 263: 'Vickers', 264: 'Walter', 265: 'Dora', 266: 'Pluto', 267: 'antlers', 268: 'Toad', 269: 'Eric', 270: 'Molinda', 271: 'Seeley', 272: 'Alonzo', 273: 'Thomas', 274: 'years', 275: 'to-night', 276: 'lama', 277: 'Methodist', 278: 'chickadee', 279: 'Frances', 280: 'Briar-patch', 281: 'Jimmy', 282: 'Montressors', 283: 'Davy', 284: 'casket', 285: 'Iarlaid', 286: 'daylight', 287: 'Simonds', 288: 'Fairweather', 289: 'Sophia', 290: 'Tilly', 291: 'Felix', 292: 'dollars', 293: 'minute', 294: 'Bill', 295: 'Bodhisat', 296: 'Mary', 297: 'Ivan', 298: 'Mungo', 299: 'Riach', 300: 'Bob', 301: 'redskins', 302: 'Sammy', 303: 'Demi', 304: 'Princess', 305: 'Emily', 306: 'Lama', 307: 'Mummy', 308: 'Carbuncle', 309: 'Laddie', 310: 'Young', 311: 'Belle', 312: 'Nan', 313: 'Ruggles', 314: 'Coon', 315: 'Ellen', 316: 'Tiidu', 317: 'Tony', 318: 'bonny', 319: 'May', 320: 'Crow', 321: 'Howe', 322: 'Halvor', 323: 'Linnet', 324: 'Judith', 325: 'nut-kernels', 326: 'Rilla', 327: 'Merediths', 328: 'Lindsay', 329: 'Longlegs', 330: 'lobsters', 331: 'Sloane', 332: 'Ceres', 333: 'Roe', 334: 'wi', 335: 'Harry', 336: 'Bessy', 337: 'harbour', 338: 'Adelia', 339: 'Ralph', 340: 'E23', 341: 'Dekkan', 342: 'Phil', 343: 'Wendy', 344: 'epistle', 345: 'Leipzig', 346: 'Hooty', 347: 'Reefer', 348: 'robins', 349: 'Joanna', 350: 'Goldthwaite', 351: 'turnovers', 352: 'Walk', 353: 'Alicia', 354: 'Esben', 355: 'Gardner', 356: 'Governor', 357: 'Kipp', 358: 'second', 359: 'Big-Horn', 360: 'Tink', 361: 'Nibs', 362: 'drowned', 363: 'tarts', 364: 'Danny', 365: 'Proserpina', 366: 'burn', 367: 'Sophie', 368: 'Maggie', 369: 'English', 370: 'Chil', 371: 'Troll', 372: 'Kirby', 373: 'Porky', 374: 'Kim', 375: 'Freda', 376: 'Minotaur', 377: 'storm', 378: 'Mas', 379: 'Snow-queen', 380: 'Turks', 381: 'barasingh', 382: 'pit-a-pat', 383: 'Kabo', 384: 'Nelly', 385: 'Witta', 386: 'George', 387: 'Lilian', 388: 'Grant', 389: 'Jill', 390: 'William', 391: 'Paddy', 392: 'Lewis', 393: 'Eliza', 394: 'Fuzzytail', 395: 'Motikatika', 396: 'Cowslip', 397: 'England', 398: 'Gulliver', 399: 'Winslow', 400: 'Madeline', 401: 'hailstones', 402: 'Waingunga', 403: 'Beacon', 404: 'stock-fish', 405: 'Covan', 406: 'Firedrake', 407: 'Catherine', 408: 'Welwa', 409: 'Selden', 410: 'James', 411: 'Duks', 412: 'Grasshopper', 413: 'Sands', 414: 'Moore', 415: 'Clark', 416: 'Bassett', 417: 'hours', 418: 'corn-barn', 419: 'Bowen', 420: 'Zengi-mizi', 421: 'Carleton', 422: 'MacPherson', 423: 'Winds', 424: 'Lancastrians', 425: 'Pan', 426: 'Marian', 427: 'Hunter', 428: 'Barnabas', 429: 'Belinda', 430: 'Amy', 431: 'Lizzie', 432: 'Miranda', 433: 'Matthew', 434: 'Baviaan', 435: 'marriage-feast', 436: 'Foxham', 437: 'Cyzicus', 438: 'Cyrilla', 439: 'Cecily', 440: 'Polly', 441: 'Temple', 442: 'Stockton', 443: 'Selena', 444: 'Puck', 445: 'efts', 446: 'Rosald', 447: 'Redwing', 448: 'Remora', 449: 'mo', 450: 'Gobbler', 451: 'fibs', 452: 'Joe', 453: 'lubbers', 454: 'Morgan', 455: 'Leo', 456: 'Simon', 457: 'Sylvia', 458: 'Ahmed', 459: 'Caleb', 460: 'Dorothy', 461: 'Scrooge', 462: 'Hubbard', 463: 'Irene', 464: 'Mamma', 465: 'Pringle', 466: 'Manawyddan', 467: 'Spencervale', 468: 'Lawson', 469: 'Romney', 470: 'flood', 471: 'Green', 472: 'month', 473: 'Maybin', 474: 'Prince', 475: 'Snowdrop', 476: 'Fred', 477: 'Lige', 478: 'Roger', 479: 'Jay', 480: 'Mahomed', 481: 'Duckworth', 482: 'Ricardo', 483: 'Tackleton', 484: 'Jacob', 485: 'Akhoonds', 486: 'Athens', 487: 'Gnat', 488: 'Ernest', 489: 'Ed', 490: 'Hoffman', 491: 'Ariadne', 492: 'Man', 493: 'Prigio', 494: 'yez', 495: 'Perseus', 496: 'Snow-man', 497: 'Ali', 498: 'Baucis', 499: 'Kotuko', 500: 'Honker', 501: 'Chuck', 502: 'Tannis', 503: 'Gudu', 504: 'Camilla', 505: 'money-lender', 506: 'lipperty-lipperty-lip', 507: 'fo', 508: 'Jerome', 509: 'Lavendar', 510: 'Ponsonby', 511: 'Grettel', 512: 'sea-beasts', 513: 'White', 514: 'Max', 515: 'Esme', 516: 'dragoons', 517: 'Spanish', 518: 'Otter', 519: 'Sikhs', 520: 'Renelde', 521: 'Molly', 522: 'Selwyn', 523: 'Dorinda', 524: 'Hutchinson', 525: 'Geraldine', 526: 'poorhouse', 527: 'Jamesina', 528: 'Vassili', 529: 'Sigurd', 530: 'Fafnir', 531: 'Hawk', 532: 'Professor', 533: 'Doctor', 534: 'cup-boards', 535: 'West', 536: 'Edith', 537: 'Biron', 538: 'Brooke', 539: 'Christopher', 540: 'Shelby', 541: 'Lloyd', 542: 'Cynthia', 543: 'Moti', 544: 'Valleyfield', 545: 'Benbow', 546: 'thrushes', 547: 'mimsy', 548: 'Hooper', 549: 'Hyde', 550: 'Sidney', 551: 'Ulysses', 552: 'Primrose', 553: 'Knowles', 554: 'Gascoigne', 555: 'Clarkman', 556: 'bulrushes', 557: 'Felicity', 558: 'First', 559: 'Maie', 560: 'Duke', 561: 'Milty', 562: 'Karela', 563: 'Chinese', 564: 'Wheeler', 565: 'Winding-Sheet', 566: 'Sweetwater', 567: 'Tabitha', 568: 'Jedediah', 569: 'Silas', 570: 'Mayflowers', 571: 'Solomon', 572: 'Gwen', 573: 'Church', 574: 'caramels', 575: 'Maria', 576: 'Whitey', 577: 'Inuit', 578: 'Babu', 579: 'Emmy', 580: 'Williamson', 581: 'Shaws', 582: 'Sara', 583: 'Halfman', 584: 'Magdalen', 585: 'Cameron', 586: 'Jesper', 587: 'round-shot', 588: 'Manus', 589: 'Petru', 590: 'Anna', 591: 'Avis', 592: 'Indian', 593: 'Earthquaker', 594: 'Davis', 595: 'Jim', 596: 'Minnie', 597: 'Jat', 598: 'Frogs', 599: 'truncheon', 600: 'weeks', 601: 'Cadmus', 602: 'Kingsport', 603: 'Sheldon', 604: 'Kay', 605: 'Heron', 606: 'Harrison', 607: 'Sarah-cat', 608: 'dromedary', 609: 'Britain', 610: 'tew', 611: 'Dad', 612: 'philter', 613: 'Alma', 614: 'Kingfisher', 615: 'Darai', 616: 'Glenby', 617: 'ef', 618: 'Aucharn', 619: 'Habogi', 620: 'Oracle', 621: 'Beanstalk', 622: 'House', 623: 'Faith', 624: 'bramble-tangle', 625: 'Inca', 626: 'muleteer', 627: 'Osborne', 628: 'Signy', 629: 'Timmy', 630: 'Merry', 631: 'Kilweh', 632: 'Hobden', 633: 'Boo', 634: 'locket', 635: 'Chester', 636: 'Eugene', 637: 'Ian', 638: 'earthquake', 639: 'princesses', 640: 'Elsa', 641: 'Leith', 642: 'Stickly-Prickly', 643: 'Charlie', 644: 'Women', 645: 'Lorelei', 646: 'Joseph', 647: 'Susette', 648: 'Phoebe', 649: 'Sipao', 650: 'Tortoise', 651: 'Stillwater', 652: 'Amoraq', 653: \"yo'alls\", 654: 'Cowan', 655: 'caw', 656: 'Enrico', 657: 'Prue', 658: 'Minnikin', 659: 'sty', 660: 'Elliott', 661: 'Kari', 662: 'Prissy', 663: 'province-house', 664: 'music-room', 665: 'colour', 666: 'dhole', 667: 'Jenny', 668: 'Bertie', 669: 'lindorm', 670: 'Andrews', 671: 'Stranger-man', 672: 'Crete', 673: 'archers', 674: 'Possums', 675: 'Jaqueline', 676: 'moat', 677: 'Stacy', 678: 'slitting-mill', 679: 'Lonsdale', 680: 'Bob-cat', 681: 'nettles', 682: 'Clow', 683: 'bouman', 684: 'Lawless', 685: 'tussock', 686: 'Neverland', 687: 'Plum', 688: 'Chiniquy', 689: 'Isabella', 690: 'lighthouse', 691: 'Gopani-Kufa', 692: 'Pygmies', 693: 'Avonlea', 694: 'Morevna', 695: 'Bellah', 696: 'Bossy', 697: 'Neil', 698: 'Teacher', 699: 'Ellis', 700: 'mouthfuls', 701: 'Periwinkle', 702: 'Suleiman-bin-Daoud', 703: 'uns', 704: 'cross-bow', 705: 'Wilbur', 706: 'Fourth', 707: 'Casimer', 708: 'Kamboh', 709: 'Dass', 710: 'Dwarf', 711: 'Sea', 712: 'croup', 713: 'Brook', 714: 'daily', 715: 'Martha', 716: 'Anderida', 717: 'Medusa', 718: 'Kitty', 719: 'Californy', 720: 'Leavitt', 721: 'elderberries', 722: 'Cyrus', 723: 'Oliver', 724: 'Curdken', 725: 'Gordon', 726: 'Redtail', 727: 'Plumy', 728: 'Lincoln', 729: 'Reeves', 730: 'ogre', 731: 'Western', 732: 'Penelope', 733: 'Owen', 734: 'Marshall', 735: 'Victor', 736: 'Josephine', 737: 'Leonard', 738: '8vo', 739: 'tureen', 740: 'Trwyth', 741: 'Hill', 742: 'Njal', 743: 'Brother', 744: 'Jonas', 745: 'Birscha', 746: 'Ellie', 747: 'Bessie', 748: 'Roderigo', 749: 'Philemon', 750: 'Karl', 751: 'Gabriel', 752: 'Aglaia', 753: 'Theseus', 754: 'henyard', 755: 'Josephina', 756: 'Cluny', 757: 'perambulators', 758: 'Phebe', 759: 'Fenwick', 760: 'Shamlegh', 761: 'China', 762: 'gorse', 763: 'Asmund', 764: 'Fatima', 765: 'Englishman', 766: 'Pinkel', 767: 'Spencer', 768: 'Hetmans', 769: 'Hetty', 770: 'Barry', 771: 'Sancho', 772: 'Alfin', 773: 'Randa', 774: 'Kangaroo', 775: 'Thyra', 776: 'Caroline', 777: 'Boston', 778: 'Mavericks', 779: 'Bennet', 780: 'Galifron', 781: 'Count', 782: 'Blacksnake', 783: 'Essendean', 784: 'shoemaker', 785: 'Auguste', 786: 'Woodchuck', 787: 'Carroll', 788: 'slew', 789: 'Buttercup', 790: 'Mustapha', 791: 'Squire', 792: 'Bella-Flor', 793: 'Eustace', 794: 'Higginbotham', 795: 'Houarn', 796: 'blindfold', 797: 'Odin', 798: 'Club', 799: 'minutes', 800: 'Yellow-Dog', 801: 'Sun', 802: 'Chugarum', 803: 'Schaibar', 804: 'Bangs', 805: 'Elizabeth', 806: 'Ken', 807: 'Starkey', 808: 'camphor-tree', 809: 'Ay', 810: 'Gaul', 811: 'Graciosa', 812: 'Tommo', 813: 'Sherman', 814: 'Hayden', 815: 'Wilfrid', 816: 'rowers', 817: 'Breezes', 818: 'Harris', 819: 'sorter', 820: 'Willard', 821: 'Henry', 822: 'Sticky-toes', 823: 'Felicia', 824: 'Pussy', 825: 'Rome', 826: 'Sona', 827: 'Breck', 828: 'Copp', 829: 'crape', 830: 'HISPANIOLA', 831: 'Niels', 832: 'MacAllisters', 833: 'shirt-collar', 834: 'Umballa', 835: 'Marquis', 836: 'Rei', 837: 'Trevlyn', 838: 'Wright', 839: 'Thakane', 840: 'Legree', 841: 'Weatherbeard', 842: 'Lillian', 843: 'toll-gatherer', 844: 'Hathi', 845: 'Rosalind', 846: 'Santlache', 847: 'dream-boy', 848: 'Pippin', 849: 'Reese', 850: 'dholes', 851: 'Toby', 852: 'Calista', 853: 'Valley', 854: 'Clorinda', 855: 'Dolmans', 856: 'Eunice', 857: 'Slowboy', 858: 'Channing', 859: 'Snowflake', 860: 'Scarecrow', 861: 'Tweedledum', 862: 'third', 863: 'towhoo', 864: 'Hancock', 865: 'madrissah', 866: 'water-demons', 867: 'Man-eater', 868: 'Frederick', 869: 'Williams', 870: 'thistles', 871: 'Philippa', 872: 'Ray', 873: 'Kennedy', 874: 'Marjorie', 875: 'Cotton', 876: 'Quack', 877: 'ALCOTT', 878: 'Bones', 879: 'Gables', 880: 'Graham', 881: 'Path', 882: 'cub', 883: 'Tootles', 884: 'Norman', 885: 'Amma', 886: 'trading-station', 887: 'Fulke', 888: 'proofs', 889: 'Asia', 890: 'Mason', 891: 'Fairbairn', 892: 'alders', 893: 'Redskin', 894: 'Gillis', 895: 'Leopard', 896: 'footprints', 897: 'Sam', 898: 'hemlock-tree', 899: 'Pat', 900: 'shinny', 901: 'Amritzar', 902: 'Jed', 903: 'McGinnis', 904: 'Naomi', 905: 'Plainfield', 906: 'Maimie', 907: 'Carabosse', 908: 'Hats', 909: 'Curtis', 910: 'greyhounds', 911: 'Scotland', 912: 'moonrise', 913: 'Allo', 914: 'disinfectants', 915: 'Bud', 916: 'choking', 917: 'Jose', 918: 'Harrington', 919: 'Walters', 920: 'Peder', 921: 'Lineik', 922: 'Hecate', 923: 'Glaucon', 924: 'Mac', 925: 'Brunhilda', 926: 'Scullion', 927: 'Sperms', 928: 'Bhagat', 929: 'Dilah', 930: 'Branch', 931: 'Amazon', 932: 'Spurgeon', 933: 'Ebenezer', 934: 'Parnesius', 935: 'Bruce', 936: 'midnight', 937: 'bullock', 938: 'Kaiser', 939: 'Wood', 940: 'Fellow', 941: 'Hai', 942: 'Buster', 943: 'Jamie', 944: 'Johnny', 945: 'Dinah', 946: 'Rosina', 947: 'Clerk', 948: 'Canadians', 949: 'Pevensey', 950: 'Emperor', 951: 'Bridget', 952: 'Day', 953: 'Towne', 954: 'Tessa', 955: 'Victoria', 956: 'Grouse', 957: 'Pertinax', 958: 'Whittington', 959: 'Trafraska', 960: 'Clarke', 961: 'Fay', 962: 'Penhallow', 963: 'Smithers', 964: 'escape', 965: 'Regnum', 966: 'Taffy', 967: 'Miner', 968: 'Xavier', 969: 'Gwrnach', 970: 'Schippeitaro', 971: 'Cratchits', 972: 'betel-box', 973: 'sick-chamber', 974: 'Houssain', 975: 'Gertrude', 976: 'archer', 977: 'Randal', 978: 'tanuki', 979: 'Eben', 980: 'Stella', 981: 'barleycorns', 982: 'Zizi', 983: 'Patterson', 984: 'Dickson', 985: 'Rankeillor', 986: 'Princesses', 987: 'lair', 988: 'Gorla', 989: 'Plumfield', 990: 'Fairy-Land', 991: 'Tiffany', 992: 'Hammond', 993: 'Hassebu', 994: 'countess', 995: 'Year', 996: 'Whittaker', 997: 'pounds', 998: 'Tabby', 999: 'Aladdin', 1000: 'Redruth', 1001: 'wands', 1002: 'Kai', 1003: 'Neverlands', 1004: 'Kaa', 1005: 'Zebra', 1006: 'Charlottetown', 1007: 'wood-box', 1008: 'Drakestail', 1009: 'Beaver', 1010: 'Blewett', 1011: 'Crag', 1012: 'Dingo', 1013: 'Ilbrahim', 1014: 'Perry', 1015: 'Byles', 1016: 'Townley', 1017: 'Antaeus', 1018: 'Shoreby', 1019: 'Ruby', 1020: 'Cratchit', 1021: 'York', 1022: 'Ingelow', 1023: 'gazelles', 1024: 'Lizard', 1025: 'Holle', 1026: 'Monkshead', 1027: 'Macgregor', 1028: 'Bentley', 1029: 'Wigglesworth', 1030: 'Jats', 1031: 'Direach', 1032: 'Prins', 1033: 'Jesse', 1034: 'tom-tom', 1035: 'aunty', 1036: 'Peronnik', 1037: 'Hansel', 1038: 'churel', 1039: 'Persian', 1040: 'cultivator', 1041: 'Allan', 1042: 'Suh', 1043: 'gate-way', 1044: 'Delhi', 1045: 'Tontlawald', 1046: 'Methodists', 1047: 'Boyd', 1048: 'empress', 1049: 'Zerah', 1050: 'Improvers', 1051: 'Eglantine', 1052: 'Archie', 1053: 'footprint', 1054: 'Hatch', 1055: 'Bewlah', 1056: 'hiding-places', 1057: 'Kerglas', 1058: 'Taylor', 1059: 'Monroe', 1060: 'Sister', 1061: 'Ogre', 1062: '_________', 1063: 'Wildrose', 1064: 'Campion', 1065: 'Baron', 1066: 'Washington', 1067: 'Man-Pack', 1068: 'Bat', 1069: 'aiggs', 1070: 'robber-girl', 1071: 'Prairies', 1072: 'Toady', 1073: 'foolscap', 1074: 'Dog', 1075: 'Dee', 1076: 'Miller', 1077: 'Greenvale', 1078: 'after-deck', 1079: 'Europa', 1080: 'Baboon', 1081: 'Armstrong', 1082: 'Jackson', 1083: 'Minon-Minette', 1084: 'Fanfaronade', 1085: 'Amal', 1086: 'Tigers', 1087: 'Sparhallow', 1088: 'vapour', 1089: 'Baxter', 1090: 'fourth', 1091: 'duckling', 1092: 'Nanny', 1093: 'Blanche', 1094: 'Aveline', 1095: 'Myra', 1096: 'shure', 1097: 'raven', 1098: 'Thumper', 1099: 'Brer', 1100: 'Scratch', 1101: 'Giovanni', 1102: 'Granny', 1103: 'Ford', 1104: 'Ichabod', 1105: 'Loker', 1106: 'Goblin', 1107: 'Damaris', 1108: 'Lucindy', 1109: 'Chrome', 1110: 'Chief', 1111: 'Shelton', 1112: 'Harmon', 1113: 'Porcupine', 1114: 'Ledyard', 1115: 'Mugger', 1116: 'hour', 1117: 'Picts', 1118: 'Richard', 1119: 'Snuffy', 1120: 'Peerybingle', 1121: 'poplars', 1122: 'Rat-a-tat-tat-tat-tat', 1123: 'Moffat', 1124: 'Hiram', 1125: 'Flint', 1126: 'Hopkins', 1127: 'Atossa', 1128: 'Caesar', 1129: 'Geirald', 1130: 'Eleanore', 1131: 'spake', 1132: 'Langton', 1133: 'Maud', 1134: 'Fletcher', 1135: 'Sodno', 1136: 'Burroughs', 1137: 'Elf', 1138: 'Clare', 1139: 'Salome', 1140: 'Ingiborg', 1141: 'Nicholas', 1142: 'Neolithic', 1143: 'Cranfield', 1144: 'petticoats', 1145: 'Stalo', 1146: 'Carol', 1147: 'tornaq', 1148: 'Christine', 1149: 'Falkenstein', 1150: 'Cabbage-Stalk', 1151: 'Kirke', 1152: 'Forrester', 1153: 'aeroplane', 1154: 'Sigismund', 1155: 'persecutors', 1156: 'Regin', 1157: 'Bryan', 1158: 'India', 1159: 'Draper', 1160: 'Toothaker', 1161: 'curtiosity', 1162: 'Pita', 1163: 'Adelon', 1164: 'Lilliput', 1165: 'Ward', 1166: 'Ripper', 1167: 'bray', 1168: 'Cinderlad', 1169: 'Bridgeport', 1170: 'garret', 1171: 'cobbler', 1172: 'Parker', 1173: 'Balfour', 1174: 'Alexina', 1175: 'Tim', 1176: 'Phoenix', 1177: 'Scott', 1178: 'organdie', 1179: 'protectors', 1180: 'Pict', 1181: 'Omar', 1182: 'Holywood', 1183: 'Red', 1184: 'drugget', 1185: 'Eurylochus', 1186: 'Henderland', 1187: 'Rajahs', 1188: 'jibs', 1189: 'Zillah', 1190: 'Lizina', 1191: 'Won-tolla', 1192: 'Gerda', 1193: 'Hamel', 1194: 'Lyda', 1195: 'Skimmer', 1196: 'yo', 1197: 'cot', 1198: 'quinine', 1199: 'Dullhead', 1200: 'Chickadee', 1201: 'Verdun', 1202: 'Deborah', 1203: 'auld', 1204: 'er', 1205: 'spiders', 1206: 'Stanley', 1207: 'Eagle', 1208: 'Mark', 1209: 'thunderbox', 1210: 'Susy', 1211: 'Whiskers-on-the-moon', 1212: 'Wakefield', 1213: 'Buldeo', 1214: 'fore-sail', 1215: 'Joan', 1216: 'Djinns', 1217: 'rose-bush', 1218: 'centre', 1219: 'Madge', 1220: 'Robert', 1221: 'Pasture', 1222: 'Irving', 1223: 'Peck', 1224: 'Courcelette', 1225: 'brooch', 1226: 'wood-pile', 1227: 'London', 1228: 'Tasek', 1229: 'Nana', 1230: 'Lucy', 1231: 'Natty', 1232: 'Dalrymple', 1233: 'week', 1234: 'Jimmu', 1235: 'Sirkar', 1236: 'hakim', 1237: 'Juno', 1238: 'nightgown', 1239: 'Abel', 1240: 'Turtle', 1241: 'Jason', 1242: 'Grey', 1243: 'pound', 1244: 'Livesey', 1245: 'Baker', 1246: 'Aina', 1247: 'Dix', 1248: 'Gunn', 1249: 'Councillors', 1250: 'tabards', 1251: 'apes', 1252: 'Clara', 1253: 'water-baby', 1254: 'Rasmus', 1255: 'Insato', 1256: 'Kinlochaline', 1257: 'Kenneth', 1258: 'Lane', 1259: 'puss', 1260: 'Elinor', 1261: 'Snodgrass', 1262: 'Place', 1263: 'Montgomery', 1264: 'phial', 1265: 'Theodosia', 1266: 'Wesley', 1267: 'Robin', 1268: 'Risingham', 1269: 'Normandy', 1270: 'Amelia', 1271: 'Appleyard', 1272: 'caddises', 1273: 'figs', 1274: 'Pivi', 1275: 'Telephassa', 1276: 'Souci', 1277: 'Helga', 1278: 'Sintram', 1279: 'pattens', 1280: 'Hindenburg', 1281: 'the', 1282: 'Clair', 1283: 'Saint', 1284: 'mayflowers', 1285: 'Arthur', 1286: 'paddy-paw', 1287: 'store-house', 1288: 'Laurin', 1289: 'Meadowby', 1290: 'leetle', 1291: 'Phillippa', 1292: 'Alphonso', 1293: 'Barlow', 1294: 'Williamsons', 1295: 'Warder', 1296: 'Hurree', 1297: 'Edward', 1298: 'Pen', 1299: 'Kirsten', 1300: 'dryad', 1301: 'Ross', 1302: 'Pharisees', 1303: 'Gator', 1304: 'bagpiper', 1305: 'Marzinne', 1306: 'Emmeline', 1307: 'weavers', 1308: 'Yowler', 1309: 'reapers', 1310: 'Snow', 1311: 'tunny', 1312: 'Rebecca', 1313: 'Elves', 1314: 'Sinclair', 1315: 'infinite-resource-and-sagacity', 1316: 'Lynnfield', 1317: 'raspberries', 1318: 'eligibles', 1319: 'Van', 1320: 'Morning', 1321: 'Montressor', 1322: 'Heidegger', 1323: 'hillmen', 1324: 'Pryor', 1325: 'Grani', 1326: 'Indians', 1327: 'Osprey', 1328: 'Right', 1329: 'Andras', 1330: 'Allardyce', 1331: 'Drew', 1332: 'Roy', 1333: 'Etin', 1334: 'salet', 1335: 'Jessie', 1336: 'Mountain', 1337: 'Priscilla', 1338: 'Lina', 1339: 'Abe', 1340: \"O'Hara\", 1341: 'Maurice', 1342: 'Owl', 1343: 'Stapp', 1344: 'French', 1345: 'Cilix', 1346: 'Braxton', 1347: 'Pryderi', 1348: 'presentiment', 1349: 'Grumbler', 1350: 'grandmamma', 1351: 'Maximus', 1352: 'Duncan', 1353: 'Rosa', 1354: 'sitting-room', 1355: 'glutton', 1356: 'Kadmiel', 1357: 'Mabon', 1358: 'clansmen', 1359: 'Water-rat', 1360: 'Ludmilla', 1361: 'Tweedle-dee', 1362: 'Nimble-Wing', 1363: 'dust-heap', 1364: 'Crows', 1365: 'red-coats', 1366: 'Isuro', 1367: 'Jean', 1368: 'Gon', 1369: 'Flora', 1370: 'Baba', 1371: 'Pygmy', 1372: 'Lark', 1373: 'Quacker', 1374: 'shoeing-tools', 1375: 'Lily', 1376: 'Ludovic', 1377: 'Di', 1378: 'beaux', 1379: 'Patto', 1380: 'Ingibjorg', 1381: 'limes', 1382: 'Markdale', 1383: 'basins', 1384: 'Eastman', 1385: 'Sikh', 1386: 'Bedwyr', 1387: 'screamer', 1388: 'Marchen', 1389: 'Titty', 1390: 'moose', 1391: 'Rosebud', 1392: 'Bellissima', 1393: 'Trevor', 1394: 'Silver', 1395: 'Ames', 1396: 'Ilonka', 1397: 'Lawrence', 1398: 'bricklayer', 1399: 'Master-maid', 1400: 'Gray', 1401: 'Adams', 1402: 'church-bells', 1403: 'wolverine', 1404: 'Tanuki', 1405: 'Frost-King', 1406: 'slabs', 1407: 'hairpins', 1408: 'British', 1409: 'Jews', 1410: 'Fritz', 1411: 'Koma', 1412: 'Beatrice', 1413: 'Cluck', 1414: 'Thorn', 1415: 'Adam', 1416: 'Dipper', 1417: 'Dapple', 1418: 'Epimetheus', 1419: 'toadstool', 1420: 'School', 1421: 'nights', 1422: 'Otto', 1423: 'hyaena', 1424: 'windac', 1425: 'Curlicue', 1426: 'Maxwell', 1427: 'Balkis', 1428: 'Fern', 1429: 'Wycherly', 1430: 'serpent-king', 1431: 'Kaban', 1432: 'Ida', 1433: 'Phillips', 1434: 'Mascot', 1435: 'Falada', 1436: 'Ada', 1437: 'Cecelia', 1438: 'Badger', 1439: 'busybody', 1440: 'Malcolm', 1441: 'Doasyoulikes', 1442: 'Afghans', 1443: 'Spirits', 1444: 'Quimus', 1445: 'Blackstone', 1446: 'Helena', 1447: 'Tit', 1448: 'Rhiannon', 1449: 'ay', 1450: 'wad', 1451: 'dory', 1452: 'Garland', 1453: 'Ao-chung', 1454: 'coffins', 1455: 'meeting-house', 1456: 'Estelle', 1457: 'Smith', 1458: 'Thistledown', 1459: 'Sebastian', 1460: 'Dawn', 1461: 'Coons', 1462: 'Frisk', 1463: 'Rat', 1464: 'General', 1465: 'Vaughns', 1466: 'pack-ice', 1467: 'Martini', 1468: 'maple-tree', 1469: 'tarkeean', 1470: 'Hummel', 1471: 'Eden', 1472: 'storekeeper', 1473: 'crowsfoot', 1474: 'Pelias', 1475: 'Messua', 1476: 'Bi-Coloured-Python-Rock-Snake', 1477: 'Phoebus', 1478: 'clogs', 1479: 'Collins', 1480: 'Nowas', 1481: 'Stamford', 1482: 'Curator', 1483: 'Koumongoe', 1484: 'Llyw', 1485: 'night-lights', 1486: 'Theodosius', 1487: 'Marya', 1488: 'Clifford', 1489: 'Cook', 1490: 'German', 1491: 'Acton', 1492: 'Gluckstein', 1493: 'Gardens', 1494: 'Um-m', 1495: 'Juliet', 1496: 'ramparts', 1497: 'Roderick', 1498: 'Gul', 1499: 'Tudor', 1500: 'Bad', 1501: 'hamadryad', 1502: 'Chris', 1503: 'Lusitania', 1504: 'pew', 1505: 'shingle', 1506: 'Haley', 1507: 'Midge', 1508: 'prickles', 1509: 'Aegeus', 1510: 'round-house', 1511: 'Tweedledee', 1512: 'Stuffy', 1513: 'Gussie', 1514: 'Wheel', 1515: 'quarantine', 1516: 'Julia', 1517: 'Snake', 1518: 'Hawkins', 1519: 'DAN', 1520: 'Mole', 1521: 'pedler', 1522: 'Seek-Seek', 1523: 'Talbot', 1524: 'dochter', 1525: 'Dhiurradh', 1526: 'Milgrave', 1527: 'Golden', 1528: 'Procrustes', 1529: 'shark', 1530: 'Bulgaria', 1531: 'Kent', 1532: 'fakeer', 1533: 'Pyes', 1534: 'Bradstreet', 1535: 'cornet', 1536: 'Godwin', 1537: 'coat-tails', 1538: 'clasps', 1539: 'milkmaid', 1540: \"o'clock\", 1541: 'Tinker', 1542: 'Seyn', 1543: 'Waters', 1544: 'Becasigue', 1545: 'Hamilton', 1546: 'Zara', 1547: 'Darby', 1548: 'Butcher', 1549: 'thrifle', 1550: 'Tamzine', 1551: 'noggin', 1552: 'Simeon', 1553: 'Chloe', 1554: 'Mordecai', 1555: 'Wiggins', 1556: 'Oah', 1557: 'stick-boat', 1558: 'spears', 1559: 'Aethra', 1560: 'Thomson', 1561: 'Swan', 1562: 'Limberheels', 1563: 'Paris', 1564: 'Abraham', 1565: 'Julius', 1566: 'Ev', 1567: 'Nekabad', 1568: 'Redmond', 1569: 'Pike', 1570: 'Desiree', 1571: 'Boomer', 1572: 'Newbury', 1573: 'Zulamith', 1574: 'Christmas-day', 1575: 'Gil', 1576: 'Capper', 1577: 'Mose', 1578: 'waiting-room', 1579: 'Crane', 1580: 'Carey', 1581: 'Ohe', 1582: 'ho', 1583: 'geraniums', 1584: 'Thornhope', 1585: 'Island', 1586: 'Whale', 1587: 'Boy', 1588: 'Flo', 1589: 'tut', 1590: 'Bhaers', 1591: 'Tassel', 1592: 'Saxon', 1593: 'goblin', 1594: 'Keefe', 1595: 'seaweeds', 1596: 'aquarium', 1597: 'Allen', 1598: 'Lyma', 1599: 'Oof', 1600: 'Oaklawn', 1601: '1.50', 1602: 'crumbs', 1603: 'alder', 1604: 'Akela', 1605: 'Lisbeth', 1606: 'Rogue', 1607: 'Sefton', 1608: 'Sy', 1609: 'Sandy', 1610: 'Adella', 1611: 'Venus', 1612: 'dominions', 1613: 'Theodora', 1614: 'Whitetail', 1615: 'Russians', 1616: 'sledge', 1617: 'button-holes', 1618: 'Liddell', 1619: 'Darlings', 1620: 'Jessamine', 1621: 'Melia', 1622: 'Anthony', 1623: 'Benares', 1624: 'Stetson', 1625: 'dressing-gown', 1626: 'Arnold', 1627: 'leper', 1628: 'prom', 1629: 'spinner', 1630: 'Kioto', 1631: 'Musician', 1632: 'ruff', 1633: 'fen', 1634: 'Steve', 1635: 'Thief', 1636: 'BOSTON', 1637: 'Moffats', 1638: 'Rilla-my-Rilla', 1639: 'Dotterine', 1640: 'palm-tree', 1641: 'Doris', 1642: 'Ethiopian', 1643: 'Rose-red', 1644: 'Fraid', 1645: 'Abdallah', 1646: 'Juliana', 1647: 'stealing', 1648: 'Morgiana', 1649: 'Roberts', 1650: 'Fire-Spirits', 1651: 'banknotes', 1652: 'Keith', 1653: 'Constance', 1654: 'Saskatchewan', 1655: 'Gilguerillo', 1656: 'Drummer', 1657: 'Salford', 1658: 'Hercules', 1659: 'heartache', 1660: 'Marchioness', 1661: 'marryin', 1662: 'evenings', 1663: 'Woods', 1664: 'Page', 1665: 'Ransome', 1666: 'Toads', 1667: 'troll', 1668: 'footmen', 1669: 'Forbes', 1670: 'Foster', 1671: 'Carter', 1672: 'hoodie', 1673: 'crab', 1674: 'Redmouth', 1675: 'Vance', 1676: 'Hare', 1677: 'Debby', 1678: 'Nouronnihar', 1679: 'Benson', 1680: 'lumberin', 1681: 'Moss', 1682: 'entreaty', 1683: 'Babylon', 1684: 'Earth', 1685: 'Matte', 1686: 'Louise', 1687: 'Chunder', 1688: 'Pris', 1689: 'Custennin', 1690: 'Kuckeliku', 1691: 'Booth', 1692: 'Bedonebyasyoudid', 1693: 'Ahtola', 1694: 'Bird', 1695: 'Nightingale', 1696: 'sun-up', 1697: 'Peters', 1698: 'Ingelows', 1699: 'Finch', 1700: 'fairyland', 1701: 'arras', 1702: 'Europe', 1703: 'coracle', 1704: 'Bluebeard', 1705: 'turnspit', 1706: 'falconers', 1707: 'Thorne', 1708: 'Lapp', 1709: 'Belsham', 1710: 'itt', 1711: 'Randall', 1712: 'Penkawr', 1713: 'cert', 1714: 'Hartley', 1715: 'Matildy', 1716: 'Crawford', 1717: 'Dosia', 1718: 'Arch', 1719: 'Elliotts', 1720: 'Elaine', 1721: 'hacks', 1722: 'Dickey', 1723: 'sunning-bank', 1724: 'tailors', 1725: 'Maypole', 1726: 'Percinet', 1727: 'Jukes', 1728: 'Brownie', 1729: 'ca-a-w', 1730: 'Riding-Hood', 1731: 'Bells', 1732: 'Pokey', 1733: 'Giraffe', 1734: 'Iolchos', 1735: 'shortbread', 1736: 'Baloo', 1737: 'Huneefa', 1738: 'Hoseason', 1739: 'rubbish-heap', 1740: 'Otters', 1741: 'crock', 1742: 'Ma', 1743: 'tanaki', 1744: 'Other-end-of-Nowhere', 1745: 'Nellie', 1746: 'rock-pools', 1747: 'Hedgehog', 1748: 'Atkinson', 1749: 'View', 1750: 'Stripey', 1751: 'Louis', 1752: 'Piper', 1753: 'kaftan', 1754: 'parlour', 1755: 'Greensnake', 1756: 'Tewara', 1757: 'Magsie', 1758: 'Willington', 1759: 'attack', 1760: 'Lobineau', 1761: 'Pirret', 1762: 'Grumpy', 1763: 'Emil', 1764: 'Friedrich', 1765: 'Hallo', 1766: 'Beaumont', 1767: 'Philip', 1768: 'oars', 1769: 'hedgehog', 1770: 'Mysa', 1771: 'Adjutant', 1772: 'Owlwood', 1773: 'Yellow-Wing', 1774: 'Tanglewood', 1775: 'cauldron', 1776: 'Soo', 1777: 'Mammy', 1778: 'Wolverine', 1779: 'Minna', 1780: 'jugs', 1781: 'tapers', 1782: 'Bond', 1783: 'silks', 1784: 'hoop-petticoat', 1785: 'Maude', 1786: 'Carmody', 1787: 'water-babies', 1788: 'Humph', 1789: 'shrieks', 1790: 'Sentner', 1791: 'Rhinoceros', 1792: 'Ye', 1793: 'Fezziwig', 1794: 'Hills', 1795: 'ahoy', 1796: 'smoking', 1797: 'wagoner', 1798: 'Colchis', 1799: 'Micky', 1800: 'Jordan', 1801: 'Cooper', 1802: 'Nora', 1803: 'quilting', 1804: 'briars', 1805: 'new-laid', 1806: 'Peppe', 1807: 'sips', 1808: 'Cunningham', 1809: 'neighbour', 1810: 'Cowardy', 1811: 'Road', 1812: 'Fluet', 1813: 'Sunnyasi', 1814: 'Frenchman', 1815: 'Sahibs', 1816: 'Manoa', 1817: 'Daintyfoot', 1818: 'tobacco', 1819: 'Octoo', 1820: 'ayah', 1821: 'Student', 1822: 'Fleece', 1823: 'Polyphemus', 1824: 'Calcutta', 1825: 'Man-Mountain', 1826: 'mollys', 1827: 'huntsmen', 1828: 'Hezekiah', 1829: 'Griggs', 1830: 'Soul', 1831: 'Bee', 1832: 'Sanch', 1833: 'Pennington', 1834: 'Nep', 1835: 'Milford', 1836: 'California', 1837: 'Arblaster', 1838: 'mas', 1839: 'kites', 1840: 'Fairies', 1841: 'Merritt', 1842: 'Riley', 1843: 'gobbler', 1844: 'Giantess', 1845: 'Madame', 1846: 'jogi', 1847: 'Joel', 1848: 'Chug-a-rum', 1849: 'Kusinagara', 1850: 'pewmonia', 1851: 'Germans', 1852: 'Flower', 1853: 'shrouds', 1854: 'moanin', 1855: 'scents', 1856: 'chink', 1857: 'Queens', 1858: 'Parsee', 1859: 'Urban', 1860: 'Lovell', 1861: 'Brownies', 1862: 'Cordelia', 1863: 'Idiots', 1864: 'Fillmore', 1865: 'old', 1866: 'Warren', 1867: 'nave', 1868: 'Solis', 1869: 'hayseed', 1870: 'Devils', 1871: 'crier', 1872: 'Pym', 1873: 'husks', 1874: 'kitchen-maid', 1875: 'Lisa', 1876: 'hermitage', 1877: 'Anderson', 1878: 'Chevalita', 1879: 'Octavia', 1880: 'Gairfowl', 1881: 'Jog', 1882: 'Yara', 1883: 'Bobby', 1884: 'huntin', 1885: 'Minos', 1886: 'Maclarens', 1887: 'Mullins', 1888: 'Bunch', 1889: 'Episcopal', 1890: 'missis', 1891: 'firs', 1892: 'effalunt', 1893: 'Dave', 1894: 'Raven', 1895: 'Jegu', 1896: 'Providence', 1897: 'hermits', 1898: 'Knight', 1899: 'Bassetts', 1900: 'Torosay', 1901: 'Christian', 1902: 'Condall', 1903: 'Anderl', 1904: 'Dart', 1905: 'Miser', 1906: 'months', 1907: 'Lily-Bell', 1908: 'Counsellor', 1909: 'Jeffrey', 1910: 'Mabel', 1911: 'sleigh', 1912: 'Grif', 1913: 'Carrolls', 1914: 'Mount', 1915: 'Kali', 1916: 'Laufer', 1917: 'gooseberries', 1918: 'Sinaubar', 1919: 'exams', 1920: 'Kellner', 1921: 'raisins', 1922: 'Uraschimataro', 1923: 'Shearer', 1924: 'Panther', 1925: 'Gruagach', 1926: 'enchantress', 1927: 'Norka', 1928: 'fringes', 1929: 'thrasher', 1930: 'Delicia', 1931: 'Evans', 1932: 'Hayes', 1933: 'Liza', 1934: 'Boulter', 1935: 'Reed', 1936: 'Manitoba', 1937: 'Howler', 1938: 'Nurse', 1939: 'Varjo', 1940: 'Medea', 1941: 'Vashti', 1942: 'shepherdess', 1943: 'housekeepers', 1944: 'Time', 1945: 'shipbuilders', 1946: 'ferryman', 1947: 'Mairtean', 1948: 'Chestercote', 1949: 'Brynhild', 1950: 'begging-bowl', 1951: 'Mogarzea', 1952: 'Tephany', 1953: 'bannock', 1954: 'cow-boy', 1955: 'hiding-place', 1956: 'CARROLL', 1957: 'Jehan', 1958: 'Kilburn', 1959: 'pine-tree', 1960: 'Deer', 1961: 'sackful', 1962: 'Presbyterian', 1963: 'Exeter', 1964: 'Cy', 1965: 'bleedin', 1966: 'wooer', 1967: 'ankus', 1968: 'heart-break', 1969: 'blade-bone', 1970: 'Jaguar', 1971: 'Khan', 1972: 'Hal', 1973: '1.25', 1974: 'trace-pin', 1975: 'Ella', 1976: 'Sahiba', 1977: 'Howard', 1978: 'stork', 1979: 'Rosetta', 1980: 'Appleby', 1981: 'Messenger', 1982: 'allers', 1983: 'Flanagin', 1984: 'Argonauts', 1985: 'malison', 1986: 'Pearson', 1987: 'Pacifique', 1988: 'Gate', 1989: 'Annette', 1990: 'petrels', 1991: 'hoppin', 1992: 'leeward', 1993: 'Lancelot', 1994: 'Almiry', 1995: 'Peacepool', 1996: 'Moppet', 1997: \"o'dreams\", 1998: 'Lynx', 1999: 'Aweel', 2000: 'chela', 2001: 'Blanchette', 2002: 'Brown-haired', 2003: 'Millers', 2004: 'Sanawar', 2005: 'Norroway', 2006: 'Parpar', 2007: 'hyaenas', 2008: 'Esterbrook', 2009: 'Denis', 2010: 'Netherby', 2011: 'Trelawney', 2012: 'swordmaker', 2013: 'Lowbridge', 2014: 'hillock', 2015: 'ear-rings', 2016: 'Beechwood', 2017: 'Mab', 2018: 'imp', 2019: 'Veldt', 2020: 'Sakatirina', 2021: 'Yaga', 2022: 'waiting-maid', 2023: 'snow-shoes', 2024: 'Huckleberry', 2025: 'horse-trader', 2026: 'Paine', 2027: 'Puffer', 2028: 'Piro', 2029: 'Carrol', 2030: 'rind', 2031: 'bath-room', 2032: 'Leon', 2033: 'Annetta', 2034: 'Marley', 2035: 'spects', 2036: 'Glutton', 2037: 'Dudley', 2038: 'stepma', 2039: 'Yspaddaden', 2040: 'Nelson', 2041: 'change-house', 2042: 'Turkey-maiden', 2043: 'Mithras', 2044: 'Katy', 2045: 'Rubens', 2046: 'Greensheve', 2047: 'humph', 2048: 'Pitman', 2049: 'Beloeil', 2050: 'Marie', 2051: 'Everett', 2052: 'Pedro', 2053: 'slippery-slide', 2054: 'Esther', 2055: 'dirk', 2056: 'hippopotamus', 2057: 'Puritan', 2058: 'Marquise', 2059: 'Connors', 2060: 'snuggery', 2061: 'Up-stairs', 2062: 'Wordsworth', 2063: 'Chamberlain', 2064: 'bairn', 2065: 'Carabas', 2066: 'Yas', 2067: 'Giddy-gaddy', 2068: 'Caucasus', 2069: 'Cinthy', 2070: 'redbreast', 2071: 'Miles', 2072: 'coral-workers', 2073: 'serpent-pit', 2074: 'ane', 2075: 'Jamila', 2076: 'shikarri', 2077: 'rosary', 2078: 'Nannette', 2079: 'wench', 2080: 'Man-cub', 2081: 'Brown-Breast', 2082: 'cheque', 2083: 'Skim', 2084: 'Miriam', 2085: 'Rexton', 2086: 'Kadlu', 2087: 'Rosette', 2088: 'Puss', 2089: 'ousel', 2090: 'spoons', 2091: 'Quaker', 2092: 'Ruais', 2093: 'angekok', 2094: 'redskin', 2095: 'Newburys', 2096: 'canes', 2097: 'ogresses', 2098: 'Huntsman', 2099: 'Jackets', 2100: 'proof-sheets', 2101: 'Pauline', 2102: 'McDougal', 2103: 'Hungary', 2104: 'dumplings', 2105: 'Speed', 2106: 'cook-house', 2107: 'Langford', 2108: 'Brahmins', 2109: 'Pond', 2110: 'Daughter', 2111: 'Ilse', 2112: 'Arrow', 2113: 'Kelso', 2114: 'Shoesmith', 2115: 'Amberley', 2116: 'Conway', 2117: 'rampion', 2118: 'Shah', 2119: 'Loon', 2120: 'Peppina', 2121: 'Beauty', 2122: 'Hook', 2123: 'Agnes', 2124: 'Koane', 2125: 'Melvin', 2126: 'Marwood', 2127: 'Borkum', 2128: 'dee', 2129: 'earthliness', 2130: 'dearie', 2131: 'pottage', 2132: 'kilta', 2133: 'beggar-woman', 2134: 'cow-house', 2135: 'mariners', 2136: 'prayer-meeting', 2137: 'Polydectes', 2138: 'Butterfly', 2139: 'Dusky', 2140: 'methinks', 2141: 'Tubby', 2142: 'Eland', 2143: 'Almas', 2144: 'Carr', 2145: 'Lee', 2146: 'water-rats', 2147: 'Helwyse', 2148: 'throttle-valve', 2149: 'Falconer', 2150: 'Walden', 2151: 'Marmee', 2152: 'soup-tureen', 2153: 'muslin', 2154: 'Tunstall', 2155: 'eighteenth', 2156: 'fortnight', 2157: 'Hairless', 2158: 'Hoffmann', 2159: 'Paperarello', 2160: 'Wizard', 2161: 'Gammas', 2162: 'Hindu', 2163: 'College', 2164: 'Veery', 2165: 'Shelley', 2166: 'noon', 2167: 'Woodrow', 2168: 'pessimist', 2169: 'Osaka', 2170: 'pii', 2171: 'faddle', 2172: 'Burnett', 2173: 'ladders', 2174: 'Thasus', 2175: 'wishbone', 2176: 'Redeye', 2177: 'Whiteland', 2178: 'Waite', 2179: 'Eaton', 2180: 'Old', 2181: 'Guard', 2182: 'fire-place', 2183: 'honeycomb', 2184: 'Quiquern', 2185: 'dog-teams', 2186: 'Cave', 2187: 'Cobra', 2188: 'Palmer', 2189: 'Quinn', 2190: 'knapsack', 2191: 'twine', 2192: 'curs', 2193: 'Grandpa', 2194: 'Cockletop', 2195: 'gossips', 2196: 'Schmidt', 2197: 'dairymaid', 2198: 'Groac', 2199: 'Capitol', 2200: 'Barkis', 2201: 'serai', 2202: 'chestnut-tree', 2203: 'himsel', 2204: 'great-coat', 2205: 'Suliman', 2206: 'Alberta', 2207: 'Humbug', 2208: 'Patypata', 2209: 'Ranza', 2210: 'dart', 2211: 'damsels', 2212: 'Esek', 2213: 'Gifts', 2214: 'dreffle', 2215: 'dahlias', 2216: 'Jameson', 2217: 'Ruskin', 2218: 'kiln', 2219: 'Potter', 2220: 'Irishwoman', 2221: 'hand-mill', 2222: 'Plummer', 2223: 'hatter', 2224: 'wampum', 2225: 'Zephyr', 2226: 'Gorgons', 2227: 'Senna', 2228: 'Montreal', 2229: 'herdsman', 2230: 'Payzant', 2231: 'Norway', 2232: 'Greenwood', 2233: 'Goshawk', 2234: 'Kimball', 2235: 'Whites', 2236: 'ridin', 2237: 'Burton', 2238: 'thongs', 2239: 'Abercrombie', 2240: 'carriage-house', 2241: 'Monroes', 2242: 'head-man', 2243: 'Whig', 2244: 'TWEEDLE', 2245: 'hen-house', 2246: 'Coward', 2247: 'jolly-boat', 2248: 'Wilson', 2249: 'Abner', 2250: 'amethysts', 2251: 'Torrance', 2252: 'Woodengown', 2253: 'Dogra', 2254: 'Buzz', 2255: 'Truth', 2256: 'retainer', 2257: 'Ismay', 2258: 'Stephens', 2259: 'May-lord', 2260: 'Cromwell', 2261: 'Contrariwise', 2262: 'DOASYOUWOULDBEDONEBY', 2263: 'Wren', 2264: 'Marooners', 2265: 'cabin-boy', 2266: 'Lurgan', 2267: 'forget-me-nots', 2268: 'Kimballton', 2269: 'Scentest', 2270: 'Andros', 2271: 'trouts', 2272: 'Open', 2273: 'Mocker', 2274: 'Night', 2275: 'Austria', 2276: 'Gatto', 2277: 'Schiraz', 2278: 'Association', 2279: 'gwine', 2280: 'collops', 2281: 'dooryard', 2282: 'Davie', 2283: 'Rollings', 2284: 'Caro', 2285: 'Bright', 2286: 'hysterics', 2287: 'Yvon', 2288: 'Glenure', 2289: 'Stewart', 2290: 'eels', 2291: 'brownie', 2292: 'kaki', 2293: 'Burr', 2294: 'ice-fairies', 2295: 'springs', 2296: 'Doran-donn', 2297: 'Cassim', 2298: 'Phao', 2299: 'Gudrun', 2300: 'fiddler', 2301: 'Killigrew', 2302: 'Lion', 2303: 'Lida', 2304: 'grandpa', 2305: 'wheelbarrow', 2306: 'Hartwell', 2307: 'Jeff', 2308: 'Wind', 2309: 'gizzard', 2310: 'Rubezahl', 2311: 'Grianaig', 2312: 'Bopsulai', 2313: 'Yankees', 2314: 'Ving', 2315: 'Banka', 2316: 'waists', 2317: 'Briggs', 2318: 'bonnets', 2319: 'sleighs', 2320: 'Vorst', 2321: 'cheque-book', 2322: 'Glenboro', 2323: 'cupola', 2324: 'hay-rick', 2325: 'Maid', 2326: 'Rock', 2327: 'Sah', 2328: 'Highlands', 2329: 'Crab', 2330: 'Portia', 2331: 'Houghton', 2332: 'Gwalchmai', 2333: 'travelling-bag', 2334: 'Bushy', 2335: 'pedlar', 2336: 'fro', 2337: 'grass-plat', 2338: 'peapods', 2339: 'Comber', 2340: 'Muffette', 2341: 'Lung-Woman', 2342: 'step-mother', 2343: 'Rochcliffe', 2344: 'Tobias', 2345: 'caddis', 2346: 'Hortense', 2347: 'Joffre', 2348: 'Cohort', 2349: 'smiths', 2350: 'Florea', 2351: 'cocoanut', 2352: 'accident', 2353: 'Diamantina', 2354: 'darning', 2355: 'sparrow', 2356: 'Ashley', 2357: 'Huzza', 2358: 'Laura', 2359: 'express-man', 2360: 'Koshchei', 2361: 'Bhaer-garten', 2362: 'Freddy', 2363: 'Wiley', 2364: 'dust-heaps', 2365: 'Grange', 2366: 'Lal', 2367: 'Cerberus', 2368: 'Timers', 2369: 'arrygory', 2370: 'Duror', 2371: 'Basset', 2372: 'hobgoblin', 2373: 'pickerel', 2374: 'Frost', 2375: 'Creighton', 2376: 'Bewick', 2377: 'Dabney', 2378: 'Fitzwarren', 2379: 'Albert', 2380: 'Buddhist', 2381: 'Oireal', 2382: 'Ahti', 2383: 'Pamelia', 2384: 'Brops', 2385: 'fireflies', 2386: 'Pine', 2387: 'Deathless', 2388: 'Fortune', 2389: 'ravens', 2390: 'Tut', 2391: 'goats', 2392: 'Pew', 2393: 'raincloud', 2394: 'Chil-maq', 2395: 'potentates', 2396: 'Stockard', 2397: 'Titania', 2398: 'Goldilocks', 2399: 'twilight', 2400: 'Chancellor', 2401: 'offence', 2402: 'Semiramis', 2403: 'Stuart', 2404: 'Sary', 2405: 'turquoises', 2406: 'Geordie', 2407: 'blueberry-patch', 2408: 'Topper', 2409: 'bandbox', 2410: 'Slow-and-Solid', 2411: 'bergman', 2412: 'Gods', 2413: 'Iliane', 2414: 'Min', 2415: 'cherub', 2416: 'Fizz', 2417: 'stalks', 2418: 'sugar-cane', 2419: 'Frewen', 2420: 'creeturs', 2421: 'pocket-book', 2422: 'hares', 2423: 'snow-drift', 2424: 'Ratibor', 2425: 'liddle', 2426: 'America', 2427: 'moonshine', 2428: 'Mitchell', 2429: 'Chrissie', 2430: 'Vizier', 2431: 'Cecil', 2432: 'Bull', 2433: 'Woodpecker', 2434: 'Envelope', 2435: 'Digger', 2436: 'reptile', 2437: 'yarbs', 2438: 'Chapley', 2439: 'murder', 2440: 'Lilias', 2441: 'yard-dog', 2442: 'Price', 2443: 'Mexican', 2444: 'snow-man', 2445: 'Peerless', 2446: 'kuyu', 2447: 'troubadour', 2448: 'Merrivale', 2449: 'Reid', 2450: 'Teddy', 2451: 'mermaids', 2452: 'Elliot', 2453: 'hearth-stone', 2454: 'Sultana', 2455: 'mussel', 2456: 'counsellors', 2457: 'Aowa', 2458: 'Bandar-log', 2459: 'flame-spirit', 2460: 'Barbaik', 2461: 'Conover', 2462: 'Shaw', 2463: 'crocodiles', 2464: 'City', 2465: 'Golden-hood', 2466: 'suet', 2467: 'under-officers', 2468: 'Spotty', 2469: 'forester', 2470: 'Luly', 2471: 'crash', 2472: 'fam', 2473: 'Hay-maker', 2474: 'sweetmeats', 2475: 'ipecac', 2476: 'sunbeam', 2477: 'hummock', 2478: 'brose', 2479: 'sunbeams', 2480: 'Mahratta', 2481: 'Paribanou', 2482: 'woodcutter', 2483: 'Dennis', 2484: 'Vevay', 2485: 'Luned', 2486: 'elves', 2487: 'Snakes', 2488: 'Claymont', 2489: 'parritch', 2490: 'Mademoiselle', 2491: 'Jennie', 2492: 'custard', 2493: 'landing-net', 2494: 'Masilo', 2495: 'Richmond', 2496: 'Butte', 2497: 'fastness', 2498: 'dears', 2499: 'gormandizers', 2500: 'Guinevere', 2501: 'boot-jack', 2502: 'Flitter', 2503: 'byre', 2504: 'Cramchild', 2505: 'Thunderfoot', 2506: 'chloroform', 2507: 'russets', 2508: 'Pigsnort', 2509: 'Champion', 2510: 'doth', 2511: 'Ditto', 2512: 'Outlier', 2513: 'Janeway', 2514: 'primrose', 2515: 'Weasel', 2516: 'Aziliez', 2517: 'cowherd', 2518: 'tabor', 2519: 'Bergen', 2520: 'afterlight', 2521: 'Charley', 2522: 'Zam-Zammah', 2523: 'Israel', 2524: 'vols', 2525: 'snippet', 2526: 'enj', 2527: 'Streatham', 2528: 'Jew', 2529: 'Jubal', 2530: 'Colburn', 2531: 'pomegranate', 2532: 'Gloucester', 2533: 'fire-box', 2534: 'Friedlin', 2535: 'Kirk', 2536: 'bear-man', 2537: 'Tetzel', 2538: 'Black-and-White', 2539: 'Gorgon', 2540: 'Marr', 2541: 'te-rain', 2542: 'gentlefolk', 2543: 'Fish', 2544: 'Italian', 2545: 'Lahore', 2546: 'Balancin', 2547: 'marcies', 2548: 'Jekyll', 2549: 'Vizir', 2550: 'Joliffe', 2551: 'Equinoxes', 2552: 'Trewin', 2553: 'Lottchen', 2554: 'heath', 2555: 'bridesmaid', 2556: 'Figs', 2557: 'McLean', 2558: 'Pittheus', 2559: 'innkeeper', 2560: 'caldron', 2561: 'marten', 2562: 'Hullo', 2563: 'Boom-oop', 2564: 'apple-leaf', 2565: 'Seymour', 2566: 'nag', 2567: 'Grafton', 2568: 'Plowden', 2569: 'Seth', 2570: 'Litill', 2571: 'melons', 2572: 'Ball-Carrier', 2573: 'serpentines', 2574: 'horseboys', 2575: 'Weatherbold', 2576: 'Daedalus', 2577: 'steersman', 2578: 'Ashton', 2579: 'Tracy', 2580: 'Angelo', 2581: 'Canary', 2582: 'Fell', 2583: 'Frasers', 2584: 'Balquhidder', 2585: 'jes', 2586: 'Pecq', 2587: 'bystanders', 2588: 'Jacky', 2589: 'Claus', 2590: 'Camel', 2591: 'Sodnos', 2592: 'octogenarian', 2593: 'Silverspot', 2594: 'milkweed', 2595: 'Turner', 2596: 'Moon', 2597: 'Beach', 2598: 'sweet-grass', 2599: 'beak', 2600: 'Swiftness', 2601: 'wood-cutter', 2602: 'Mayor', 2603: 'Finland', 2604: 'chiffon', 2605: 'Mischief', 2606: 'Appin', 2607: 'faqir', 2608: 'Tiger-lily', 2609: 'Fly-catcher', 2610: 'machans', 2611: 'Matey', 2612: 'Nell', 2613: 'Maynard', 2614: 'spunk', 2615: 'pannikin', 2616: 'drugs', 2617: 'warblers', 2618: 'Hessian', 2619: 'Gulch', 2620: 'bazar', 2621: 'eft', 2622: 'lightning', 2623: 'Blish', 2624: 'tassel', 2625: 'Croyden', 2626: 'Good-morning', 2627: 'carbuncle', 2628: 'yeou', 2629: 'palings', 2630: 'MacCallum', 2631: 'co-eds', 2632: 'Servant', 2633: 'shroud', 2634: 'Holmes', 2635: 'Ephraim', 2636: 'shoon', 2637: 'Wey', 2638: 'dimness', 2639: 'Matty', 2640: 'Ducks', 2641: 'Bertram', 2642: 'Yo', 2643: 'stone-cutter', 2644: 'Shute', 2645: 'Dansville', 2646: 'Hassan', 2647: 'C25', 2648: 'poisoned', 2649: 'cypher', 2650: 'truncheons', 2651: 'horsey', 2652: 'guineas', 2653: 'berths', 2654: 'Cartonville', 2655: 'Bow-wow', 2656: 'upholsterer', 2657: 'Nquing', 2658: 'Berwick', 2659: 'capful', 2660: 'Dashwood', 2661: 'maidservant', 2662: 'Violet', 2663: 'Lad', 2664: 'Lauretta', 2665: 'Centurion', 2666: 'dyspepsia', 2667: 'Imp', 2668: 'sugar-house', 2669: 'half-pint', 2670: 'brocades', 2671: 'garlands', 2672: 'Lake', 2673: 'sultana', 2674: 'Harmer', 2675: 'Burchard', 2676: 'choked', 2677: 'lindworm', 2678: 'Grumbly', 2679: 'Everlastin', 2680: 'States', 2681: 'Delphi', 2682: 'sire', 2683: 'town-crier', 2684: 'Sparhallows', 2685: 'Chiron', 2686: 'Amend-All', 2687: 'carryall', 2688: 'Pickwick', 2689: 'bogs', 2690: 'Antonio', 2691: 'cross-roads', 2692: 'Grier', 2693: 'carpet-bag', 2694: 'cookery', 2695: 'saddlers', 2696: \"yo'all\", 2697: 'Modron', 2698: 'Parson', 2699: 'lan', 2700: 'philtre', 2701: 'cents', 2702: 'land-babies', 2703: 'Doodle', 2704: 'Blake', 2705: 'Mess-tent', 2706: 'Antoine', 2707: 'Eua', 2708: 'Archidej', 2709: 'Florrie', 2710: 'cabbages', 2711: 'marrocks', 2712: 'bamboo', 2713: 'Longworth', 2714: 'oilskin', 2715: 'town-pump', 2716: 'Whitgift', 2717: 'forfeits', 2718: 'programme', 2719: 'Judson', 2720: 'Kitty-mouse', 2721: 'Ullah', 2722: 'Summerside', 2723: 'Sparrow', 2724: 'Kubbee', 2725: 'Elias', 2726: 'witching', 2727: 'Corkscrew', 2728: 'Leicester', 2729: 'Lincolnshire', 2730: 'Lucia', 2731: '6_s', 2732: 'Point', 2733: 'Glasgow', 2734: 'Linda', 2735: 'Bluff', 2736: 'Duchess', 2737: 'Spirit-Bear', 2738: 'independent', 2739: 'Padre', 2740: 'Greek', 2741: 'Napoleon', 2742: 'Brewster', 2743: 'Yap-Yap', 2744: 'cutler', 2745: 'Maharanee', 2746: 'Trent', 2747: 'buttermilk', 2748: 'Smollett', 2749: 'Jacko', 2750: 'chirp', 2751: 'mercies', 2752: 'Kabir', 2753: 'bairagi', 2754: 'Churchill', 2755: 'cut-aa-cut', 2756: 'Jonah', 2757: 'Sire', 2758: 'Perak', 2759: 'Nash', 2760: 'Fiske', 2761: 'baboon', 2762: 'Africa', 2763: 'Sloan', 2764: 'Loo', 2765: 'emery', 2766: 'fleece', 2767: 'Viola', 2768: 'ohe', 2769: 'Greece', 2770: 'Hagar', 2771: 'terrors', 2772: 'astronomers', 2773: 'parchments', 2774: 'Cerisette', 2775: 'sled', 2776: 'Pachacamac', 2777: 'Hesperides', 2778: 'Locksley', 2779: 'Haigha', 2780: 'wedding-veil', 2781: 'daytime', 2782: 'Timothy', 2783: 'fir-tree', 2784: 'Tritill', 2785: 'wazirs', 2786: 'Francisco', 2787: 'Southland', 2788: 'Ethel', 2789: 'Hudson', 2790: 'zither', 2791: 'Grinnell', 2792: 'man-of-war', 2793: 'Skinner', 2794: 'Cupids', 2795: 'prairies', 2796: 'vim', 2797: 'Lea', 2798: 'borogoves', 2799: 'stepsister', 2800: 'Rennie', 2801: 'tap-hole', 2802: 'Chaplain', 2803: 'seal-meat', 2804: 'Zeppelin', 2805: 'Lennox', 2806: 'beetle', 2807: 'sair', 2808: 'Chi-dubula-taka', 2809: 'Connor', 2810: 'pussies', 2811: 'pancakes', 2812: 'Falls', 2813: 'Esquint', 2814: 'Dutch', 2815: 'gemplum', 2816: 'Fet-Fruners', 2817: 'Browns', 2818: 'jasmine', 2819: 'Busan', 2820: 'acorn', 2821: 'plums', 2822: 'goblet', 2823: 'pats', 2824: 'Harthover', 2825: 'Snow-white', 2826: 'caste-mark', 2827: 'birthdays', 2828: 'grazing-grounds', 2829: 'palisade', 2830: 'Bright-eyes', 2831: 'Nqong', 2832: 'Palfrey', 2833: 'sma', 2834: 'Milkweed', 2835: 'Talus', 2836: 'Redcoats', 2837: 'coxswain', 2838: 'watchman', 2839: 'contrariness', 2840: 'pick-axe', 2841: 'blunderbuss', 2842: 'sun-nap', 2843: 'Gracie', 2844: 'folio', 2845: 'Poet', 2846: 'ag', 2847: 'Tina', 2848: 'ridgepole', 2849: 'Ow', 2850: 'woodman', 2851: 'Harvard', 2852: 'dat', 2853: 'Gratian', 2854: 'Hells', 2855: 'midges', 2856: 'doughnut', 2857: 'Spy-glass', 2858: 'Lesley', 2859: 'Martara', 2860: 'Bunar', 2861: 'sleeping-room', 2862: 'Shuan', 2863: 'Russell', 2864: 'Lotty', 2865: 'shu-ya', 2866: 'pea', 2867: 'firth', 2868: 'Pendexter', 2869: 'Smithsons', 2870: 'Lilith', 2871: 'Volaterrae', 2872: 'mouse-trap', 2873: 'ammonia', 2874: 'doughnuts', 2875: 'Ambassador', 2876: 'promontory', 2877: 'water-path', 2878: 'Chanty', 2879: 'Copely', 2880: 'Saddhu', 2881: 'moonglade', 2882: 'Burnley', 2883: 'Weland', 2884: 'Law', 2885: 'yelpings', 2886: 'Lazarre', 2887: 'fraid-cat', 2888: 'Chesters', 2889: 'castes', 2890: 'moor', 2891: 'Gopher', 2892: 'Chup', 2893: 'emblem', 2894: 'Campbells', 2895: 'gimble', 2896: 'Mhow', 2897: 'Cæsar', 2898: 'sepulchre', 2899: 'city-hall', 2900: 'Lambs', 2901: 'Wylde', 2902: 'forecastle', 2903: 'Larkins', 2904: 'Turley', 2905: 'Hughes', 2906: 'Mirror', 2907: 'authoress', 2908: 'Council', 2909: '1.00', 2910: 'mutineers', 2911: 'scullions', 2912: 'Hebe', 2913: 'goose-boy', 2914: 'dahlia', 2915: 'Pie', 2916: 'Fawn', 2917: 'Sid', 2918: 'Anastasia', 2919: 'unicorn', 2920: 'Kensington', 2921: 'Nillie', 2922: 'Ellenwood', 2923: 'Freshmen', 2924: 'Gilman', 2925: 'Owlsdark', 2926: 'jib', 2927: 'Stavanger', 2928: 'beaver-swamp', 2929: 'Stanton', 2930: 'Davy-boy', 2931: 'Iveragh', 2932: 'Cecco', 2933: 'troll-hag', 2934: 'Evergreens', 2935: 'Admiral', 2936: 'Bedford', 2937: 'Queen-mother', 2938: 'permanency', 2939: 'Laud', 2940: 'scythes', 2941: 'shoal', 2942: 'public-house', 2943: 'gooseberry', 2944: 'Guide', 2945: 'horse-shoer', 2946: 'Grandmamma', 2947: 'Simurgh', 2948: 'tormentors', 2949: 'Bible', 2950: 'Ardan', 2951: 'Porter', 2952: 'Dippy', 2953: 'Winkle', 2954: 'buttercup', 2955: 'leopard', 2956: 'Jerusha', 2957: 'ruttees', 2958: 'hemlock', 2959: 'Avenue', 2960: 'knave', 2961: 'Abdullah', 2962: 'sea-birds', 2963: 'Chapman', 2964: 'within-doors', 2965: 'Cotch', 2966: 'hammers', 2967: 'Colorado', 2968: 'coo', 2969: 'Muskrats', 2970: 'Reds', 2971: 'Grace', 2972: 'florins', 2973: 'Poland', 2974: 'Si', 2975: 'embers', 2976: 'elands', 2977: 'fish-pond', 2978: 'sech', 2979: 'rhododendrons', 2980: 'missus', 2981: 'radishes', 2982: 'downwards', 2983: 'Ikki', 2984: 'Accadee', 2985: 'charcoal-burners', 2986: 'talisman', 2987: 'Cramond', 2988: 'drowse', 2989: 'Alin', 2990: 'braid', 2991: 'Jimsie', 2992: 'bazars', 2993: 'Priest', 2994: 'Brackley', 2995: 'Warsaw', 2996: 'teapot', 2997: 'Carewe', 2998: 'didst', 2999: 'Baive', 3000: 'carp-fish', 3001: 'DonNELL', 3002: 'Vendale', 3003: 'eighth', 3004: 'sea-shore', 3005: 'People', 3006: 'tummin', 3007: 'Crusoe', 3008: 'burdocks', 3009: 'Lou', 3010: 'Quakers', 3011: 'God', 3012: 'Speckle', 3013: 'schoolmasters', 3014: 'Glewlwyd', 3015: 'Turkey', 3016: 'Stana', 3017: 'Hatta', 3018: 'Shasasa', 3019: 'ware-room', 3020: 'CA', 3021: 'letter-writer', 3022: 'Frost-Spirits', 3023: 'Roxy', 3024: 'Trenton', 3025: 'Mahomet', 3026: 'court-yard', 3027: 'landlady', 3028: 'snowflake', 3029: 'bird-catcher', 3030: 'Lawler', 3031: 'splendour', 3032: 'mourner', 3033: 'Countess', 3034: 'Wilfy', 3035: 'Waq', 3036: 'Joshua', 3037: 'Dandy', 3038: 'Guthrum', 3039: 'Proctor', 3040: 'Hist', 3041: 'Harvey', 3042: 'pantaloons', 3043: 'Hummer', 3044: 'enuff', 3045: 'Malazy', 3046: 'pincushion', 3047: 'Holloway', 3048: 'Grabugeon', 3049: 'Slope', 3050: 'rubbers', 3051: 'door-nail', 3052: 'Quetta', 3053: 'Keyton-Wells', 3054: 'Callman', 3055: 'Halifax', 3056: 'Bhotiyal', 3057: 'Puruna', 3058: 'rat-a-tat-tat-tat', 3059: 'scalesome', 3060: 'Turkish', 3061: 'hydra', 3062: 'Bayside', 3063: 'stepdaughter', 3064: 'Venetian', 3065: 'Giant', 3066: 'Maclaren', 3067: 'Nymphs', 3068: 'Valdez', 3069: 'Ca', 3070: 'Ethnological', 3071: 'hurricane', 3072: 'Aids', 3073: 'quillies', 3074: 'sugar-rose', 3075: 'violence', 3076: 'Bunyip', 3077: 'Chirp', 3078: 'storm-cloud', 3079: 'hogshead', 3080: 'Dunbar', 3081: 'Abbey', 3082: 'Duck', 3083: 'Nautilus', 3084: 'Plouhinec', 3085: 'ragamuffin', 3086: 'satyrs', 3087: 'Conservatives', 3088: 'Orchard', 3089: 'Vogelstein', 3090: 'Dunnoo', 3091: 'Cox', 3092: 'Oo', 3093: 'Kennedys', 3094: 'sea-thief', 3095: 'Lyall', 3096: 'mommer', 3097: 'fever-trees', 3098: 'Carrier', 3099: 'Penhallows', 3100: 'Queenslea', 3101: 'Kungla', 3102: 'Noah', 3103: 'Aslauga', 3104: 'Pig-girl', 3105: \"M'Graw\", 3106: 'Himalayan', 3107: 'Rich', 3108: 'grandmere', 3109: 'mammy', 3110: 'gnats', 3111: 'Rose-tree', 3112: 'sea-weeds', 3113: 'Radnor', 3114: 'diks', 3115: 'headman', 3116: 'Canada', 3117: 'pig-girl', 3118: 'Aetes', 3119: 'Ferryman', 3120: 'Cora', 3121: 'Philemen', 3122: 'Vectis', 3123: 'Devil', 3124: 'Bacon', 3125: 'Cobras', 3126: 'Downy-Back', 3127: 'awa', 3128: 'Tibet', 3129: 'Sallie', 3130: 'skein', 3131: 'river-sucker', 3132: 'dominie', 3133: 'goose-girl', 3134: 'Jenkins', 3135: 'Margie', 3136: 'Marmar', 3137: 'Hur', 3138: 'bank-note', 3139: 'Cow', 3140: 'Bristol', 3141: 'Hereford', 3142: 'Wall', 3143: 'bar-room', 3144: 'naebody', 3145: 'pumpkins', 3146: 'counting-house', 3147: 'house-hunting', 3148: 'Destiny', 3149: 'Annice', 3150: 'lipperty', 3151: 'Tiber', 3152: 'Angelina', 3153: 'cup-bearer', 3154: 'haid', 3155: 'colours', 3156: 'Mahabodhi', 3157: 'curl-papers', 3158: 'Latifa', 3159: 'Phoe-be', 3160: 'bed-post', 3161: 'Afar', 3162: 'Waal', 3163: 'Bernard', 3164: 'Chiswick', 3165: 'Olwen', 3166: 'Pharaoh', 3167: 'Bergmann', 3168: 'Falsom', 3169: 'Robby', 3170: 'Cecilia', 3171: 'Aaron', 3172: 'Nucklao', 3173: 'Cynthy', 3174: 'manger', 3175: 'Powwow', 3176: 'paddling', 3177: 'ticket-office', 3178: 'Star-Light', 3179: 'Flathead', 3180: 'Pyrotechnist', 3181: 'sar', 3182: 'Enchanter', 3183: 'Anon', 3184: 'cucumber', 3185: 'Mannering', 3186: 'Widow-maker', 3187: 'Koodoo', 3188: 'Dartmouth', 3189: 'Argo', 3190: 'white-faces', 3191: 'Heatherton', 3192: 'Vane', 3193: 'AVERIL', 3194: 'gorver', 3195: 'fig-tree', 3196: 'boardinghouse', 3197: 'fourpenny', 3198: 'cheroot-case', 3199: 'gamekeeper', 3200: 'Leigh', 3201: 'Riddell', 3202: 'birstle', 3203: 'sea-king', 3204: 'hake', 3205: 'Willoughby', 3206: 'Pudding', 3207: 'Rogear', 3208: 'brither', 3209: 'Clipsby', 3210: 'pucker', 3211: 'Stalos', 3212: 'shrew', 3213: 'Swift', 3214: 'Shakespeare', 3215: 'Punjab', 3216: 'Norton', 3217: 'Brats', 3218: 'camphor', 3219: 'pack-saddle', 3220: 'Gordons', 3221: 'downy', 3222: 'fib', 3223: 'lamassery', 3224: 'Italy', 3225: 'Nighthawk', 3226: 'Kun', 3227: 'window-sill', 3228: 'Walrus', 3229: 'cloister', 3230: 'Dil-aram', 3231: 'Lewes', 3232: 'yoursel', 3233: 'Emory', 3234: 'lye', 3235: 'langurs', 3236: 'Florence', 3237: 'nyamatsane', 3238: 'Kamakura', 3239: 'nosegay', 3240: 'Pologne', 3241: 'blacker', 3242: 'whales', 3243: 'Pika', 3244: 'school-room', 3245: 'demi-cannon', 3246: 'finery', 3247: 'Adamses', 3248: 'Brandan', 3249: 'Daly', 3250: 'Barton', 3251: 'blue-birds', 3252: 'Peterson', 3253: 'Flossie', 3254: 'Almira', 3255: 'crayon', 3256: 'Im', 3257: 'Millward', 3258: 'Rissaldar', 3259: 'pottet-knife', 3260: 'Cancaline', 3261: 'Banks', 3262: 'korigan', 3263: 'Segedunum', 3264: 'Hoot-toot', 3265: 'Jove', 3266: 'hearthstone', 3267: 'Nathoo', 3268: 'neck-handkerchief', 3269: 'Kulu', 3270: 'pundit', 3271: 'feeding-places', 3272: 'hill-man', 3273: 'undress', 3274: 'nyamatsanes', 3275: 'Hummels', 3276: 'Braddon', 3277: 'turnip', 3278: 'Quicksilver', 3279: 'foster-brother', 3280: 'hoppy-hippy-hippy-hop-o', 3281: 'Dilber', 3282: 'Bahr', 3283: 'home-acre', 3284: 'Pickerel', 3285: 'Swallow', 3286: 'Bride', 3287: 'Mittwoch', 3288: 'pellet', 3289: 'murders', 3290: 'Puritans', 3291: 'Avesnes', 3292: 'cobs', 3293: 'Fulkes', 3294: 'Khaistan', 3295: 'whelps', 3296: 'gulls', 3297: 'scythe', 3298: 'Sleipnir', 3299: 'Lapland', 3300: 'Ash', 3301: 'man-smell', 3302: 'Samson', 3303: 'Fiddler', 3304: 'snow-flake', 3305: 'sho', 3306: 'sackcloth', 3307: 'Kailung', 3308: 'spring-root', 3309: 'sperrits', 3310: 'aeroplanes', 3311: 'surcoat', 3312: 'FROST', 3313: 'grasshopper', 3314: 'Bumble', 3315: 'Eph', 3316: 'beaus', 3317: 'Evora', 3318: 'washerman', 3319: 'Brop', 3320: 'Elder', 3321: 'steeds', 3322: 'Tower', 3323: 'puncheon', 3324: 'Electa', 3325: 'Walworth', 3326: 'Blakes', 3327: 'hyacinth', 3328: 'bobbin', 3329: 'Ding', 3330: 'Pierson', 3331: 'Sloanishness', 3332: 'Union', 3333: 'chick-a-dee-dee', 3334: 'tarlaton', 3335: 'Ghaut', 3336: 'day-nursery', 3337: 'Laptitza', 3338: 'Kismet', 3339: 'Ding-dong', 3340: 'moonbeams', 3341: 'chinook', 3342: 'Conservative', 3343: 'South', 3344: 'hag', 3345: 'Hamlet', 3346: 'owl-rays', 3347: 'Parnassus', 3348: 'Quick-ear', 3349: 'MacAllister', 3350: 'Hunno', 3351: 'Mamie', 3352: 'Kieva', 3353: 'natal-shore', 3354: 'godfather', 3355: 'auctions', 3356: 'damosel', 3357: 'Mugger-Ghaut', 3358: 'Janeiro', 3359: 'chimney-sweeps', 3360: 'great-uncle', 3361: 'Itchi', 3362: 'driftwood', 3363: 'tuft', 3364: 'Sarah', 3365: 'Mull', 3366: 'Nursey', 3367: 'girlhood', 3368: 'gaoler', 3369: 'Himalayas', 3370: 'Barons', 3371: 'Stirling', 3372: 'President', 3373: 'secretest', 3374: 'Kiddies', 3375: 'Mack', 3376: 'hind-legs', 3377: 'Langdon', 3378: 'Haulbowline', 3379: 'Room', 3380: 'Laylocks', 3381: 'sea-weed', 3382: 'Goldie', 3383: 'Mercer', 3384: 'lettuce', 3385: 'tornait', 3386: 'Demophoon', 3387: 'Madison', 3388: 'Speckles', 3389: 'Lear', 3390: 'Thuggai', 3391: 'Christ', 3392: 'narcissi', 3393: 'Flanders', 3394: 'Lancaster', 3395: 'huntsman', 3396: 'twelvemonth', 3397: 'Eliott', 3398: 'Donnell', 3399: 'Hanselpakker', 3400: 'Japan', 3401: 'blindman', 3402: 'Nqa', 3403: 'flower-pot', 3404: 'Sampson', 3405: 'bakers', 3406: 'coverlids', 3407: 'icicles', 3408: 'duns', 3409: 'sleeping-bench', 3410: 'Bright-eye', 3411: 'sparrows', 3412: 'vermin', 3413: 'Rutter', 3414: 'Millison', 3415: 'charcoal-burner', 3416: 'merry-makers', 3417: 'prayer-book', 3418: 'Lock-out', 3419: 'Yeats', 3420: 'Braithwaite', 3421: 'follicles', 3422: 'Rutilianus', 3423: 'Tennyson', 3424: 'Bruno', 3425: 'medlars', 3426: 'Olsen', 3427: 'Briar', 3428: 'Hi', 3429: 'Mihr-afruz', 3430: 'Brewsters', 3431: 'Gullfaxi', 3432: 'Yah', 3433: 'Russian', 3434: 'maize', 3435: 'Honour', 3436: 'cuckoo', 3437: 'Phineas', 3438: 'culvert', 3439: 'grotto', 3440: 'quilts', 3441: 'twig', 3442: 'Lindorm', 3443: 'witchcraft', 3444: 'Preston', 3445: 'golden-rod', 3446: 'mid-day', 3447: 'Angus', 3448: 'milliner', 3449: 'yew', 3450: 'evergreens', 3451: 'Chick', 3452: 'step-sister', 3453: 'scullion', 3454: 'swimmer', 3455: 'Balachulish', 3456: 'Tyndal', 3457: 'Northfield', 3458: 'Marjory', 3459: 'Tewindrow', 3460: 'Brahmin', 3461: 'te-train', 3462: 'signet', 3463: 'mysel', 3464: 'Scamp', 3465: 'Fo', 3466: 'Godling', 3467: 'sateen', 3468: 'rowing', 3469: 'Meroz', 3470: 'elderberry', 3471: 'Irish', 3472: 'Djulung', 3473: 'hoodies', 3474: 'snobbishness', 3475: 'torture', 3476: 'dawut', 3477: 'windward', 3478: 'babble', 3479: 'juniper', 3480: 'Chinaman', 3481: 'perambulator', 3482: 'madamoiselle', 3483: 'herrings', 3484: 'Argus', 3485: 'Bemis', 3486: 'equerry', 3487: 'Elizabethan', 3488: 'Gavial', 3489: 'hoard', 3490: 'Andrew', 3491: 'crab-fairy', 3492: 'wrench', 3493: 'reeds', 3494: 'quarter', 3495: 'Rosamond', 3496: 'Venice', 3497: 'Paradise', 3498: 'Jeanette', 3499: 'Aleck', 3500: 'tippet', 3501: 'Lair', 3502: 'Jerusalem', 3503: 'Bravo', 3504: 'Gillespie', 3505: 'grey-green', 3506: 'castle-hall', 3507: 'Dandelion', 3508: 'Florimond', 3509: 'Lucknow', 3510: 'Beetle', 3511: 'Carpenter', 3512: 'polypes', 3513: 'Blot', 3514: 'tidies', 3515: 'Tree', 3516: 'Walsingham', 3517: 'Street', 3518: 'Dublin', 3519: 'handicraft', 3520: 'Bonnach', 3521: 'Hopetown', 3522: 'Carlisle', 3523: 'corn-crib', 3524: 'spring-hole', 3525: 'buttercups', 3526: 'Rememberest', 3527: 'Know-all', 3528: 'gruel', 3529: 'oncet', 3530: 'story-teller', 3531: 'tumult', 3532: 'lily-pads', 3533: 'Edwin', 3534: 'Monghyr', 3535: 'Bebe', 3536: 'hen-wife', 3537: 'trumpeters', 3538: 'Terrace', 3539: 'Inlet', 3540: 'Hyacinth', 3541: 'Milton', 3542: 'Navarre', 3543: 'corsets', 3544: 'Montreaux', 3545: 'tattletale', 3546: 'Gaeta', 3547: 'Morrison', 3548: 'Egypt', 3549: 'Colin', 3550: 'Matheson', 3551: 'Saharunpore', 3552: 'stern-port', 3553: 'chargers', 3554: 'Polish', 3555: 'JO', 3556: 'inglenook', 3557: 'dream-child', 3558: 'fagot-maker', 3559: 'Gooseberry', 3560: 'Centaur', 3561: 'conjurer', 3562: 'Slow-Solid', 3563: 'Dove', 3564: 'Cary', 3565: 'ob', 3566: 'chums', 3567: 'laird', 3568: 'Rosy-face', 3569: 'Dhu', 3570: 'Dean', 3571: 'Hippocrates', 3572: 'Patriotism', 3573: 'Mussalmans', 3574: 'Dumont', 3575: 'plum-cake', 3576: 'Irishman', 3577: 'Brenda', 3578: 'Bowman', 3579: 'Lochlann', 3580: 'Lok', 3581: 'resting-place', 3582: 'Toueno-Boueno', 3583: 'crag', 3584: 'habitation', 3585: 'father-boy', 3586: 'Power', 3587: 'Atlantic', 3588: 'jester', 3589: 'neighing', 3590: 'Columbus', 3591: 'cravat', 3592: 'Corcoran', 3593: 'smartness', 3594: 'Serpentine', 3595: 'Riversdale', 3596: 'landladies', 3597: 'Saverne', 3598: 'wood-cutters', 3599: 'duster', 3600: 'Rogerson', 3601: 'Ern', 3602: 'Feely', 3603: 'Blythes', 3604: 'disease', 3605: 'Snoreonski', 3606: 'Pilgrims', 3607: 'Mither', 3608: 'kun', 3609: 'firewood', 3610: 'Winthrop', 3611: 'Halliday', 3612: 'Daimio', 3613: 'Unpitied', 3614: 'Murrain', 3615: 'Jemima', 3616: 'tea-chest', 3617: 'Adah', 3618: 'Gorilla', 3619: 'enchanter', 3620: 'Lowlands', 3621: 'Flagg', 3622: 'trew', 3623: 'Mayblossom', 3624: 'Delia', 3625: 'Partridge', 3626: 'American', 3627: 'Lu-Lu', 3628: 'Stute', 3629: 'curiosities', 3630: 'Alexandria', 3631: 'dovekies', 3632: 'midday', 3633: 'Chan', 3634: 'Bekir', 3635: 'Gwawl', 3636: 'Cove', 3637: 'Sedna', 3638: 'heal-well', 3639: 'Curry', 3640: 'Sailors', 3641: 'Fift', 3642: 'Red-tail', 3643: 'Mocking-bird', 3644: 'Hawkwood', 3645: 'M.P.s', 3646: 'Gwrhyr', 3647: 'chimney-sweep', 3648: 'Blewitt', 3649: 'Will', 3650: 'eaglets', 3651: 'icebergs', 3652: 'Yap-yap-yap', 3653: 'Betsey', 3654: 'pommel', 3655: 'Subida', 3656: 'Mr', 3657: 'shentleman', 3658: 'Aline', 3659: 'Lo', 3660: 'abaout', 3661: 'spare-room', 3662: 'Marion', 3663: 'lozenges', 3664: 'R17', 3665: 'ditto', 3666: 'water-drops', 3667: 'cow-path', 3668: 'France', 3669: 'purchaser', 3670: 'arbutus', 3671: 'futures', 3672: 'ratcatcher', 3673: 'Jack-the-Chatterer', 3674: 'fez', 3675: 'peradventure', 3676: 'Pinehurst', 3677: 'dumb-bells', 3678: 'Cleopatra', 3679: 'Ethiopia', 3680: 'Grip', 3681: 'weekly', 3682: 'Steel', 3683: 'Hilas', 3684: 'Saunders', 3685: 'Whizz', 3686: 'Dallington', 3687: 'carbuncles', 3688: 'Teshumai', 3689: 'Serbia', 3690: 'up-stairs', 3691: 'Pole', 3692: 'Farm', 3693: 'baize', 3694: 'Phrixus', 3695: 'brier', 3696: 'croquet', 3697: 'Nathaniel', 3698: 'Parliament', 3699: 'Klondike', 3700: 'Samuel', 3701: 'Bo-Peep', 3702: 'oop', 3703: 'gillies', 3704: 'Pilrig', 3705: 'solemner', 3706: 'Cutter', 3707: 'Watkins', 3708: 'Liberals', 3709: 'Burney', 3710: 'tablecloth', 3711: 'Bryant', 3712: 'Hindfell', 3713: 'Marsh', 3714: 'fiord', 3715: 'jackals', 3716: 'Fulsom', 3717: 'snuff', 3718: 'perfessun', 3719: 'housings', 3720: 'Iona', 3721: 'morn', 3722: 'dragon-fly', 3723: 'Hind', 3724: 'Geryon', 3725: 'there-was', 3726: 'Jandiala', 3727: 'Pip', 3728: 'Polynesia', 3729: 'Bronte', 3730: 'earthquakes', 3731: 'Vale', 3732: 'Taram-taq', 3733: 'aspens', 3734: 'Loch', 3735: 'rock-slide', 3736: 'Jains', 3737: 'singing-birds', 3738: 'man-eater', 3739: 'boarding-school', 3740: 'eaves', 3741: 'birch-bark', 3742: 'Crookback', 3743: 'fly-leaf', 3744: 'Heather', 3745: 'diviners', 3746: 'Bolingbroke', 3747: 'Adoniram', 3748: 'Chauncey', 3749: 'dulness', 3750: 'bullocks', 3751: 'Frutilla', 3752: 'Josiah', 3753: 'Stewarts', 3754: 'Prakora', 3755: 'Serai', 3756: 'All-the-Elephant-there-was', 3757: 'Tun', 3758: 'Pelion', 3759: 'stile', 3760: 'Firedrakes', 3761: 'bulwarks', 3762: 'Brooks', 3763: 'Cicely', 3764: 'Picus', 3765: 'ethnologist', 3766: 'Thuu', 3767: 'Lancers', 3768: 'Dorman', 3769: 'nestlings', 3770: 'Lalage', 3771: 'Looking-Glass', 3772: 'Christy', 3773: 'boxing-gloves', 3774: 'blood-trail', 3775: 'Rita', 3776: 'dont', 3777: 'stools', 3778: 'posies', 3779: 'Pooh', 3780: 'scorpion', 3781: 'Cottons', 3782: 'Lexy', 3783: 'Blackcap', 3784: 'hearth-fire', 3785: 'sandal', 3786: 'measuring-tree', 3787: 'Hardy', 3788: 'clachan', 3789: 'twelfth', 3790: 'lassie', 3791: 'horse-truck', 3792: 'lanyard', 3793: 'settin', 3794: 'Lafayette', 3795: 'Baccy', 3796: 'smarts', 3797: 'Tetterbys', 3798: 'toothache', 3799: 'ducats', 3800: 'waggon', 3801: 'Guddhu', 3802: 'Emma', 3803: 'Kettley', 3804: 'Portland', 3805: 'Gardiner', 3806: 'knocker', 3807: 'Buddhism', 3808: 'Towhit', 3809: 'Barrett', 3810: 'Woodlands', 3811: 'Nicaea', 3812: 'Dickeys', 3813: 'Earraid', 3814: 'Blanchet', 3815: 'Sprott', 3816: 'wardrobes', 3817: 'doodle-doo', 3818: 'Douceline', 3819: 'cockchafer', 3820: 'Adair', 3821: 'sardine', 3822: 'Arundel', 3823: 'Danish', 3824: 'Christianity', 3825: 'kinsmen', 3826: 'North', 3827: 'Roughleg', 3828: 'catechist', 3829: 'dimples', 3830: 'Yep', 3831: 'Simla', 3832: 'mullein', 3833: 'criers', 3834: 'master-thief', 3835: 'grouse-eggs', 3836: 'Trojan', 3837: 'Squash-blossom', 3838: 'ROBERTS', 3839: 'Lamb', 3840: 'Persia', 3841: 'Cap', 3842: 'Jen', 3843: 'barrack-school', 3844: 'Bey', 3845: 'Hatfield', 3846: 'accidents', 3847: 'Samarcand', 3848: 'Rest-and-be-Thankful', 3849: 'Embree', 3850: 'glade', 3851: 'balsam', 3852: 'pug', 3853: 'Gad', 3854: 'flower-roots', 3855: 'Robbery', 3856: 'beagles', 3857: 'Kitchener', 3858: 'suc-cess-ion', 3859: 'Douglases', 3860: 'collop', 3861: 'sacque', 3862: 'fish-house', 3863: 'Ironhead', 3864: 'Creek', 3865: 'scroll', 3866: 'Ashland', 3867: 'Fane', 3868: 'extinguisher', 3869: 'Dodge', 3870: 'Sit-in-the-kitchen', 3871: 'Jud', 3872: 'apricots', 3873: 'cabbage-leaf', 3874: 'Cross', 3875: 'Siah', 3876: 'Pathan', 3877: 'wren', 3878: 'Agassiz', 3879: 'window-panes', 3880: 'Marne', 3881: 'Blacklock', 3882: 'doggy', 3883: 'Delancey', 3884: 'Goldsmith', 3885: 'evaporator', 3886: 'sweeties', 3887: 'Mann', 3888: 'Chickaree', 3889: 'Sunbeam', 3890: 'Ridge', 3891: 'Josy-phine', 3892: 'Bengali', 3893: 'kraal', 3894: 'hawser', 3895: 'pea-hens', 3896: 'Presbytery', 3897: 'cocoa-nuts', 3898: 'flutes', 3899: 'winks', 3900: 'Psyche', 3901: 'Troezene', 3902: 'bedstead', 3903: 'Granville', 3904: 'Peshawur', 3905: 'dustmen', 3906: 'Andy', 3907: 'Huns', 3908: 'Gleeson', 3909: 'Bruin', 3910: 'dressing-room', 3911: 'rosebud', 3912: 'Hindi', 3913: 'mither', 3914: 'summer-house', 3915: 'night-cap', 3916: 'Rangs', 3917: 'Larry', 3918: 'Gerty', 3919: 'meshes', 3920: 'rejoicings', 3921: 'snow-storm', 3922: 'Neguses', 3923: 'Crocker', 3924: 'Rat-a-tat-tat-tat', 3925: 'death-knot', 3926: 'Boulters', 3927: 'astern', 3928: 'woodbox', 3929: 'Toueno', 3930: 'Edinburgh', 3931: 'Helène', 3932: 'Christmas-tide', 3933: 'Mary-creature', 3934: 'Barbara', 3935: 'Looking-over', 3936: 'Principal', 3937: '16mo', 3938: 'assault', 3939: 'Agenor', 3940: 'Volcano', 3941: 'Cribson', 3942: 'wing', 3943: 'Presbyterians', 3944: 'after-times', 3945: 'Castle', 3946: 'Rozennik', 3947: 'Corrynakiegh', 3948: 'Ann', 3949: 'chariots', 3950: 'Tataka', 3951: 'Andvari', 3952: 'YEARS', 3953: 'TOVES', 3954: 'Wilhelm', 3955: 'Petkin', 3956: 'Yankee', 3957: 'Greene', 3958: 'Wilhelmina', 3959: 'Aunties', 3960: 'Xenophon', 3961: 'cooties', 3962: 'nohow', 3963: 'Rapunzel', 3964: 'spruce-tree', 3965: 'doilies', 3966: 'autographs', 3967: 'Atlas', 3968: 'Aua', 3969: 'Lory', 3970: 'Kempis', 3971: 'Charta', 3972: 'Amonoosuck', 3973: 'pompon', 3974: 'Frisky', 3975: 'Djinn', 3976: 've', 3977: 'Yank', 3978: 'Ring', 3979: 'Raymond', 3980: 'Qamas', 3981: 'wood-pigeon', 3982: 'Girl', 3983: 'royaliness', 3984: 'duel', 3985: 'scalps', 3986: 'pestilence', 3987: 'peppermint', 3988: 'Millar', 3989: 'racecourse', 3990: 'Ardshiel', 3991: 'whisker', 3992: 'bucketful', 3993: 'Raksha', 3994: 'Rebel', 3995: 'shaws', 3996: 'dinner-ball', 3997: 'Lynceus', 3998: 'Urdu', 3999: 'ninepins', 4000: 'malcontents', 4001: 'Prayer-meeting', 4002: 'valour', 4003: 'Shafto', 4004: 'Bed-curtains', 4005: 'cartes', 4006: 'Ooryas', 4007: 'dingle', 4008: 'dung-cake', 4009: 'wood-pigeons', 4010: 'mumps', 4011: 'Drudwyn', 4012: 'Charlottas', 4013: 'Pii', 4014: 'snow-line', 4015: 'Lehon', 4016: 'Come-and-never-go', 4017: 'whither', 4018: 'prevaricator', 4019: 'Cufic', 4020: 'Cracker', 4021: 'Penningtons', 4022: 'Abby', 4023: 'Normans', 4024: 'Maywater', 4025: 'Throgmorton', 4026: 'Penny', 4027: 'arbour', 4028: 'Robins', 4029: 'stalk', 4030: 'Campden', 4031: 'Leonora', 4032: 'Ambrosius', 4033: 'Leh', 4034: 'dandelions', 4035: 'Olivers', 4036: 'hay-stack', 4037: 'alehouse', 4038: 'unfairness', 4039: 'Olga', 4040: 'Hickory-tree', 4041: 'European', 4042: 'Yo-ho-ho', 4043: 'Odo', 4044: 'Court', 4045: 'chimney-corner', 4046: 'McGinnises', 4047: 'Bumpsterhausen', 4048: 'Dunno', 4049: 'foot-ball', 4050: 'pea-hen', 4051: 'Frenchwoman', 4052: 'Killarney', 4053: 'Smash-up', 4054: 'thatch', 4055: 'Catharine', 4056: 'whopper', 4057: 'Crick', 4058: 'anemones', 4059: 'Kisika', 4060: 'harebells', 4061: 'gigs', 4062: 'Horace', 4063: 'chime', 4064: 'cryin', 4065: 'Reformatories', 4066: 'Ptthmllnsprts', 4067: 'Sound', 4068: 'heralds', 4069: 'linden-tree', 4070: 'Chick-a-dee-dee', 4071: 'Maccolls', 4072: 'Bottom', 4073: 'cake-crumbs', 4074: 'Taseks', 4075: 'girl-daughter', 4076: 'testimonies', 4077: 'Limpopo', 4078: 'goat-slayer', 4079: 'Salem', 4080: 'feedle', 4081: 'verdure', 4082: 'Maine', 4083: 'Sigmunds', 4084: 'iceberg', 4085: 'Cloverside', 4086: 'strawberry', 4087: 'Hall', 4088: 'nocht', 4089: 'mattress', 4090: 'Daventry', 4091: 'men-at-arms', 4092: 'sea-urchins', 4093: 'Enderly', 4094: 'Milligan', 4095: 'Marysville', 4096: 'schoolteacher', 4097: 'nightly', 4098: 'Beni', 4099: 'Alder', 4100: 'Plunkett', 4101: 'Ice', 4102: 'boars', 4103: 'Harbour', 4104: 'Northumbria', 4105: 'Spices', 4106: 'hiccoughs', 4107: 'Precession', 4108: 'house', 4109: 'Society', 4110: 'execution', 4111: 'nativities', 4112: 'Truce', 4113: 'night-caps', 4114: 'Mammon', 4115: 'bannisters', 4116: 'Albania', 4117: 'cocks', 4118: 'placard', 4119: 'dreadf', 4120: 'TENNIEL', 4121: 'water-lets', 4122: 'Hippopotamus', 4123: 'Glover', 4124: 'Herrings', 4125: 'wort', 4126: 'Fisher', 4127: 'fish-basket', 4128: 'ermine', 4129: 'Lillibullero', 4130: 'Text', 4131: 'All-the-Cow-there-was', 4132: 'Hippolyta', 4133: 'Franklin', 4134: 'Brom', 4135: 'Animal', 4136: 'surety', 4137: 'wayfarers', 4138: 'barks', 4139: 'villas', 4140: 'cherry-stone', 4141: 'executions', 4142: 'snow-house', 4143: 'Blunderbore', 4144: 'Bothwell', 4145: 'Sol', 4146: 'mush', 4147: 'Feathertoes', 4148: 'wabe', 4149: 'flit', 4150: 'Jungle-Favour', 4151: 'Ziglaur', 4152: 'Allfowlsness', 4153: 'Patrick', 4154: 'Mercia', 4155: 'cucumbers', 4156: 'heroines', 4157: 'Tai', 4158: 'Parmalee', 4159: 'Christians', 4160: 'Parks', 4161: 'bob-o-link', 4162: 'gen', 4163: 'shellfish', 4164: 'trifles', 4165: 'bairns', 4166: 'Girouette', 4167: 'Boaster', 4168: 'Haq', 4169: 'Kotgarh', 4170: 'Bisnagar', 4171: 'WABE', 4172: 'Morristown', 4173: 'Shakejoint', 4174: 'Ally', 4175: 'luff', 4176: 'befo', 4177: 'king-lion', 4178: 'camp-fire', 4179: 'Tippy-toppy-tippy-toe', 4180: 'bowsprit', 4181: 'Tucker', 4182: 'coolies', 4183: 'hayloft', 4184: 'Harmonia', 4185: 'pecking', 4186: 'Koran', 4187: 'Biebrich', 4188: 'pantries', 4189: 'ablution', 4190: 'Dawes', 4191: 'hay-cart', 4192: 'Rangely', 4193: 'Downy', 4194: 'Voice', 4195: 'Kynon', 4196: 'Heresy', 4197: 'Binkie', 4198: 'Purr', 4199: 'fakirs', 4200: 'Atwater', 4201: 'snowdrift', 4202: 'Eb', 4203: 'cross-trees', 4204: 'bunches', 4205: 'corn-cob', 4206: 'Dane', 4207: 'Kerry', 4208: 'Martins', 4209: 'dooli', 4210: 'Bank', 4211: 'jelly-fish', 4212: 'Erin', 4213: 'Peace', 4214: 'Anglo-Saxon', 4215: 'shadow-time', 4216: 'Kelpy', 4217: 'georgette', 4218: 'recitations', 4219: 'Harpies', 4220: 'Danae', 4221: 'Mariner', 4222: 'Khitai', 4223: 'Candle', 4224: 'work-basket', 4225: 'Yorkists', 4226: 'Morley', 4227: 'bethink', 4228: 'gros', 4229: 'Queensferry', 4230: 'jack-knife', 4231: 'Flynn', 4232: 'fruitatives', 4233: 'Buda', 4234: 'gatepost', 4235: 'Village', 4236: 'Devereux', 4237: 'Ludlow', 4238: 'lugger', 4239: 'lilies-of-the-valley', 4240: 'mosquitos', 4241: 'Laurences', 4242: 'Somme', 4243: 'bullock-cart', 4244: 'pheeal', 4245: 'barrens', 4246: 'forsworn', 4247: 'Gunpowder', 4248: 'toll-house', 4249: 'bull-fight', 4250: 'Mau-giri', 4251: 'voile', 4252: 'spyglass', 4253: 'TOWN-PUMP', 4254: 'Havana', 4255: 'laddie', 4256: 'Summer-Wind', 4257: 'figure-head', 4258: 'Harper', 4259: 'Fasting', 4260: 'Sooty-back', 4261: 'Bailey', 4262: 'Vadso', 4263: \"o'nights\", 4264: 'Marcy', 4265: 'frights', 4266: 'Kong', 4267: 'man-at-arms', 4268: 'lead-bullocks', 4269: 'Lindens', 4270: 'gorilla', 4271: 'Au', 4272: 'godson', 4273: 'Fayal', 4274: 'Randolph', 4275: 'rumour', 4276: 'boarders', 4277: 'deer-sinews', 4278: 'Chikai', 4279: 'Harriet', 4280: 'Pollock', 4281: 'mountain-side', 4282: 'Doc', 4283: 'Encyclopedia', 4284: 'Nice', 4285: 'Barrys', 4286: 'palaver', 4287: 'Caddy', 4288: 'daisy', 4289: 'Breeze', 4290: 'Tulip', 4291: 'Boom-bitty', 4292: 'lubber', 4293: 'haunch', 4294: 'gingerbread', 4295: 'Blauvor', 4296: 'Willa', 4297: 'Merlin', 4298: 'Mussoorie', 4299: 'cowyard', 4300: 'Galligantus', 4301: 'Dolphus', 4302: 'trefoil', 4303: 'band-box', 4304: 'Ithaca', 4305: 'weeping-beech', 4306: 'Lions', 4307: 'Slade', 4308: 'Berton', 4309: 'sceptre', 4310: 'Broughton', 4311: 'Rogers', 4312: 'Fenne', 4313: 'parao', 4314: 'langur', 4315: 'Morris', 4316: 'Jacobite', 4317: 'hillocks', 4318: 'Matilda', 4319: 'nite', 4320: 'bladder', 4321: 'Fie', 4322: 'Kelpie', 4323: 'Gutok', 4324: 'elf', 4325: 'Ox', 4326: 're-sponsi-bil-ity', 4327: 'labor', 4328: 'Cresty', 4329: 'match-girl', 4330: 'Australia', 4331: 'Seeonee', 4332: 'shorry', 4333: 'Teblinski', 4334: 'God-speed', 4335: 'Lena', 4336: 'dog-cart', 4337: 'Lion-driver', 4338: 'Podurellae', 4339: 'Bunny-house', 4340: 'Peterboro', 4341: 'Weller', 4342: 'Uhh', 4343: 'Wal', 4344: 'beavers', 4345: 'Rhody', 4346: 'Kingdom', 4347: 'Trunk', 4348: 'mannie', 4349: 'hay-mow', 4350: 'barnacles', 4351: 'husk', 4352: 'postilions', 4353: 'grandchild', 4354: 'lisp', 4355: 'Eastern', 4356: 'A-sitting', 4357: 'murasla', 4358: 'carding-comb', 4359: 'Company', 4360: 'Leader', 4361: 'explosion', 4362: 'gudgeons', 4363: 'do-oo-oo', 4364: 'mane', 4365: 'mendy-bag', 4366: 'mowers', 4367: 'Fiji', 4368: 'Prospect', 4369: 'partridges', 4370: 'Gleason', 4371: 'Byrne', 4372: 'Minister', 4373: 'Craig', 4374: 'Carson', 4375: 'asp', 4376: 'kinsman', 4377: 'Spiti', 4378: 'Grundy', 4379: 'comforter', 4380: 'sharpers', 4381: 'Constantine', 4382: 'Ferao', 4383: 'grewel', 4384: 'Frame', 4385: 'deary', 4386: 'Petrograd', 4387: 'cotton-factories', 4388: 'betimes', 4389: 'Hilli-ho', 4390: 'grouse', 4391: 'Bijah', 4392: 'rose-buds', 4393: 'palanquin', 4394: 'Gond', 4395: 'leathern', 4396: 'castor-oil', 4397: 'ogres', 4398: 'fagots', 4399: 'chit', 4400: 'home-lessons', 4401: 'twa', 4402: 'Master-word', 4403: 'cakies', 4404: 'Dogger', 4405: 'walking-stick', 4406: 'cherry-tree', 4407: 'Chicago', 4408: 'Bancroft', 4409: 'Desert', 4410: 'HOWE', 4411: 'Knave', 4412: 'defences', 4413: 'Shadow', 4414: 'Cramp', 4415: 'snub', 4416: 'Bexlei', 4417: 'cowcumbers', 4418: 'Warden', 4419: 'Isobel', 4420: 'Riverside', 4421: 'optician', 4422: 'civilities', 4423: 'Row', 4424: 'quarters', 4425: 'hay-cock', 4426: 'Jain', 4427: 'wonder-ship', 4428: 'Plunger', 4429: 'Sunday-school', 4430: 'Parmelee', 4431: 'Metanira', 4432: 'spanking', 4433: 'twenty-pounders', 4434: 'Millwards', 4435: 'Judy', 4436: 'Thankee', 4437: 'Cookson', 4438: 'Mead', 4439: 'Cert', 4440: 'Mimi', 4441: 'Marmot', 4442: 'Jip', 4443: 'Carrie', 4444: 'sarks', 4445: 'horse-shoes', 4446: 'hater', 4447: 'clasp', 4448: 'playfellow', 4449: 'Borden', 4450: 'Akali', 4451: 'Magdalens', 4452: 'causeway', 4453: 'serpentskin', 4454: 'Ferozepore', 4455: 'Khanhiwara', 4456: 'All-the-Beaver-there-was', 4457: 'Longfellow', 4458: 'brushwood', 4459: 'Windfoot', 4460: 'Bates', 4461: 'fascinator', 4462: 'Guenevere', 4463: 'Southern', 4464: 'Sweet', 4465: 'Marm', 4466: 'birth-certificate', 4467: 'Annabella', 4468: 'Phineus', 4469: 'Qaf', 4470: 'Mandersons', 4471: 'blackberries', 4472: 'horseshoes', 4473: 'oar', 4474: 'school-girl', 4475: 'hornets', 4476: 'Kirbys', 4477: 'Beeches', 4478: 'kinks', 4479: 'Doughty', 4480: 'bao-babs', 4481: 'Carvell', 4482: 'farm-house', 4483: 'mair', 4484: 'Ronald', 4485: 'Army', 4486: 'vampire', 4487: 'Blimber', 4488: 'Grayson', 4489: 'Ahoy', 4490: 'murdered', 4491: 'Bucharest', 4492: 'chain-man', 4493: 'silly-hoot', 4494: 'Lorenzo', 4495: 'Bobbles', 4496: 'seizin', 4497: 'Hent', 4498: 'Hawksley', 4499: 'narcissus', 4500: 'goldenrod', 4501: 'Virgil', 4502: 'Aie', 4503: 'Muffet', 4504: 'Scotia', 4505: 'Susie', 4506: 'equerries', 4507: 'hornet', 4508: 'Keene', 4509: 'birch-rod', 4510: 'Willie', 4511: 'southernwood', 4512: 'needlework', 4513: 'Plato', 4514: 'distaff', 4515: 'Aha', 4516: 'tumblers', 4517: 'Medbourne', 4518: 'knot-hole', 4519: 'Thrush', 4520: 'Theodore', 4521: 'wool-wains', 4522: 'centuries', 4523: 'headstone', 4524: 'Pool', 4525: 'Nick', 4526: 'invisibility', 4527: 'Cupid', 4528: 'geranium', 4529: 'sea-moths', 4530: 'vegetable-man', 4531: 'Dhole', 4532: 'circlet', 4533: 'visor', 4534: 'Pethick', 4535: 'Alexander', 4536: 'chaffinch', 4537: 'Witch', 4538: 'goose-house', 4539: 'sorcerer', 4540: 'Putte', 4541: 'porch-door', 4542: 'wood-flowers', 4543: 'Mayen', 4544: 'Mogul', 4545: 'lanthorn', 4546: 'Brookdale', 4547: 'aout', 4548: 'Noel', 4549: 'morning-glories', 4550: 'fifteenth', 4551: 'Pallas', 4552: 'man-meat', 4553: 'Eliot', 4554: 'Edgartown', 4555: 'Peg', 4556: 'Valrosa', 4557: 'Tahmasp', 4558: 'SCRAP-BAG', 4559: 'pedlars', 4560: 'Mirabel', 4561: 'arm-pit', 4562: 'father-in-law', 4563: 'Jadoo-Gher', 4564: 'goldsmiths', 4565: 'Greaves', 4566: 'Egerton', 4567: 'Darkness', 4568: 'Canadian', 4569: 'Devil-child', 4570: 'Pineau', 4571: 'moustaches', 4572: 'dishcloth', 4573: 'Lodz', 4574: 'blood-money', 4575: 'scamps', 4576: 'ante-room', 4577: 'Toledo', 4578: 'dragonfly', 4579: 'Kidd', 4580: 'worm-shop', 4581: 'Butou', 4582: 'Bridge', 4583: 'flyleaf', 4584: 'bhisti', 4585: 'Bradshaw', 4586: 'wauken', 4587: 'Jungle', 4588: 'hangings', 4589: 'Montague', 4590: 'Hamley', 4591: 'Mang', 4592: 'Looking-glass', 4593: 'play-bill', 4594: 'Tck', 4595: 'Bhurtpore', 4596: 'gunwale', 4597: 'Hanover', 4598: 'Titian', 4599: 'thunderstorm', 4600: 'Westbury', 4601: 'Baden-Baden', 4602: 'Tirthankars', 4603: 'penitence', 4604: 'chimney-piece', 4605: 'Ju', 4606: 'cuds', 4607: 'smote', 4608: 'Tintin', 4609: 'pitu', 4610: 'tourney', 4611: 'Maol-mor', 4612: 'herring-net', 4613: 'Bolgolam', 4614: 'Sailor', 4615: 'stepfather', 4616: 'sledges', 4617: 'Netty', 4618: 'Labor', 4619: 'mangers', 4620: 'stane', 4621: 'sneeze', 4622: 'pinwheels', 4623: 'Jaunia', 4624: 'Nu-endo', 4625: 'ter', 4626: 'Violetta', 4627: 'Fielding', 4628: 'Gazer', 4629: 'bedclothes', 4630: 'Maclean', 4631: 'Ragotte', 4632: 'candy-scrape', 4633: 'Kalka', 4634: 'dabs', 4635: 'Desdemona', 4636: 'Gertie', 4637: 'Cornelius', 4638: 'Chesapeake', 4639: 'portmanteau', 4640: 'frying-pan', 4641: 'llama', 4642: 'All-the-Turtle-there-was', 4643: 'Hood', 4644: 'unbelievers', 4645: 'humbug', 4646: 'gillie', 4647: 'sorceress', 4648: 'ud', 4649: 'Ras', 4650: 'Hope', 4651: 'wazir', 4652: 'Dee-dee-chickadee', 4653: 'birch-stub', 4654: 'Dew-Drop', 4655: 'Oak-tree', 4656: 'brillig', 4657: 'urchin', 4658: 'Porthos', 4659: 'Dreamland', 4660: 'Parr', 4661: 'ruby', 4662: 'Trolls', 4663: 'Battle', 4664: 'Haig', 4665: 'Cockawee', 4666: 'Holt', 4667: 'enchantments', 4668: 'Brimstone', 4669: 'Caraccas', 4670: 'amends', 4671: 'Oriental', 4672: 'Wexbridge', 4673: 'purr', 4674: 'foresters', 4675: 'small-pox', 4676: 'wretches', 4677: 'Shannon', 4678: 'genies', 4679: 'buttonhole', 4680: 'loiterer', 4681: 'Morcar', 4682: 'great-great-ever-so-great-grandfather', 4683: 'Leiths', 4684: 'lovelornity', 4685: 'Anne-girl', 4686: 'leeve', 4687: 'rood', 4688: 'fust', 4689: 'matrons', 4690: 'WonderBook', 4691: 'woodpile', 4692: 'Bose', 4693: 'pneumonia', 4694: 'dogfish', 4695: 'ALICE', 4696: 'extravagance', 4697: 'landing-place', 4698: 'water-snakes', 4699: 'oast-house', 4700: 'councillors', 4701: 'grippe', 4702: 'tramps', 4703: 'hasty-pudding', 4704: 'brat', 4705: 'GIMBLE', 4706: 'Bhai', 4707: '4_s', 4708: 'couriers', 4709: 'shaganappies', 4710: 'deil', 4711: 'Othere', 4712: 'patronising', 4713: 'foxes', 4714: 'surf-wave', 4715: 'Bliss', 4716: 'clew', 4717: 'primmynum', 4718: 'unkle', 4719: 'nightgowns', 4720: 'Georgie', 4721: 'phaeton', 4722: 'drem', 4723: 'mange', 4724: 'Bert', 4725: 'idolaters', 4726: 'Dey', 4727: 'grace-notes', 4728: 'seventh', 4729: 'swarvin', 4730: 'Selby', 4731: 'whirr', 4732: 'Chronicles', 4733: 'bizness', 4734: 'rick', 4735: 'Josephs', 4736: 'faggots', 4737: 'Whitefield', 4738: 'Pater', 4739: 'Japanese', 4740: 'wedding-dress', 4741: 'flapjack', 4742: 'Portuguese', 4743: 'Dutchmen', 4744: 'tin-wagon', 4745: 'Koalisnacoan', 4746: 'shivers', 4747: 'Mascalucia', 4748: 'propensity', 4749: 'Hazard', 4750: 'Arlington', 4751: 'Trevlyns', 4752: 'Hennebonne', 4753: 'Buktanoos', 4754: 'carnations', 4755: 'drying-poles', 4756: 'bandboxes', 4757: 'scarecrow', 4758: 'compasses', 4759: 'Merry-Andrew', 4760: 'yearlings', 4761: 'century', 4762: 'Shrike', 4763: 'Gairfowlskerry', 4764: 'dimple', 4765: 'Examiner', 4766: 'hoondi', 4767: 'Bloomer', 4768: 'Cath', 4769: 'Raphael', 4770: 'eno', 4771: 'Murre', 4772: 'lavendar', 4773: 'Woons', 4774: 'Riverton', 4775: 'Bronson', 4776: 'queue', 4777: 'bramble', 4778: 'Lowland', 4779: 'Ogden', 4780: 'tea-party', 4781: 'new-and-all', 4782: 'conceit', 4783: 'matadore', 4784: 'nilghai', 4785: 'Dodo', 4786: 'hogsheads', 4787: 'madrepores', 4788: 'cottage-wall', 4789: 'Rambler', 4790: 'Canterbury', 4791: 'Rhine', 4792: 'psalms', 4793: 'wincey', 4794: 'sweeper', 4795: 'Buchanan', 4796: 'churls', 4797: 'Hutetu', 4798: 'heedlessness', 4799: 'Gog', 4800: 'Febilla', 4801: \"Hallowe'en\", 4802: 'Requiem', 4803: 'gyre', 4804: 'Pinery', 4805: 'We-uns', 4806: 'flatirons', 4807: 'islet', 4808: 'waistband', 4809: 'Tununirmiut', 4810: 'sea-loch', 4811: 'dovecote', 4812: 'matey', 4813: 'Flume', 4814: 'Notch', 4815: 'ells', 4816: 'mutton-ham', 4817: 'collier-boys', 4818: 'Ripple', 4819: 'salt-pans', 4820: 'hoe', 4821: 'admiral', 4822: 'Plums', 4823: 'Stimson', 4824: 'Jabberwock', 4825: 'dishonour', 4826: 'Virginny', 4827: 'Dicksons', 4828: 'mohwa', 4829: 'gravestones', 4830: 'penitentiary', 4831: 'Blackmore', 4832: 'Deer-park', 4833: 'Siam', 4834: 'oat', 4835: 'sticklebacks', 4836: 'citrons', 4837: 'Brunswick', 4838: 'piper', 4839: 'Amie', 4840: 'teeny', 4841: 'sermon-time', 4842: 'Hatschihime', 4843: 'townspeople', 4844: 'Goldtown', 4845: 'Bailiff', 4846: 'trellis', 4847: 'Lobster', 4848: 'Tide-wave', 4849: 'Allahabad', 4850: 'Crawfords', 4851: 'quarter-gallery', 4852: 'Wensleydale', 4853: 'Cornwall', 4854: 'cavalcade', 4855: 'Rahmatabad', 4856: 'Rodney', 4857: 'tucket', 4858: 'Friedel', 4859: 'Althea', 4860: 'Injun', 4861: 'feeler', 4862: 'tartan', 4863: 'seaward', 4864: 'Psst', 4865: 'Whereat', 4866: 'Marsden', 4867: 'fifes', 4868: 'Ventnor', 4869: 'garden', 4870: 'Chitor', 4871: 'predestination', 4872: 'Golden-Wing', 4873: 'boy-brother', 4874: 'primroses', 4875: 'checkers', 4876: 'Na', 4877: 'flower-pots', 4878: 'Salisbury', 4879: 'Zambesi', 4880: \"G'way\", 4881: 'shot-window', 4882: 'paddles', 4883: 'Lyman', 4884: 'Falcon', 4885: 'county', 4886: 'Bradley', 4887: 'Job', 4888: 'shoemakers', 4889: 'lyre', 4890: 'valise', 4891: 'Hee-tee-tee-hee-e-e-e', 4892: 'tankard', 4893: 'lobs', 4894: 'bookstore', 4895: 'Willowmere', 4896: 'pigpen', 4897: 'council-hall', 4898: 'hussars', 4899: 'Dilaram', 4900: 'Subtraction', 4901: 'engine-house', 4902: 'Oha', 4903: 'Berkshire', 4904: 'Sigurds', 4905: 'heathens', 4906: 'stuffin', 4907: 'almshouse', 4908: 'Kneader', 4909: 'three-thirds', 4910: 'Kitt', 4911: 'Phelps', 4912: 'white-cliffs-of-Albion', 4913: 'SLITHY', 4914: 'Froda', 4915: 'Flicker', 4916: 'idolater', 4917: 'lodger', 4918: 'Strong', 4919: 'pulses', 4920: 'market-gardener', 4921: 'millpond', 4922: 'fishing-rod', 4923: 'Allonby', 4924: 'spinifex', 4925: 'Longitude', 4926: 'Mus', 4927: 'poetrys', 4928: 'aour', 4929: 'wood-lot', 4930: 'rose-leaves', 4931: 'Cinderwench', 4932: 'Agra', 4933: 'Moody', 4934: 'rose-tree', 4935: 'Meow', 4936: 'nightcap', 4937: 'shallows', 4938: 'treachery', 4939: 'overlord', 4940: 'aught', 4941: 'ricks', 4942: 'Huxley', 4943: 'darlings', 4944: 'Englishmen', 4945: 'juniper-tree', 4946: 'pung', 4947: 'Stickytoes', 4948: 'sound-pictures', 4949: 'Rah', 4950: 'satchel', 4951: 'Hah', 4952: 'moles', 4953: 'fancy-work', 4954: 'brook-side', 4955: 'picture-letter', 4956: 'Grandpapa', 4957: 'meal-chest', 4958: 'egg-beater', 4959: 'creter', 4960: 'Balti', 4961: 'thumps', 4962: 'Tomtoddies', 4963: 'Markham', 4964: 'Pa', 4965: 'Severin'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# modelCBTNE = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = len(label_names))\n",
        "modelCBTNE = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", id2label=id2label, label2id=label2id)\n",
        "# modelCBTNE.cuda()\n",
        "training_args = TrainingArguments(\n",
        "\toutput_dir=\"/content/drive/My Drive/ColabNotebooks/model out/\",\n",
        "\t# optim = \"adamw_torch\", \n",
        "\tevaluation_strategy=\"steps\", \n",
        "\t#num_train_epochs = 10,\n",
        "\tmetric_for_best_model = \"accuracy\",\n",
        "\tgreater_is_better = True,\n",
        "  # warmup_steps = 5000,\n",
        "\t# save_steps=5000,\n",
        "\t# max_steps = 25000,\n",
        "\t# eval_steps = 5000,\n",
        "  warmup_steps = 50,\n",
        "\tsave_steps=50,\n",
        "\tmax_steps = 100,\n",
        "\teval_steps = 50,\n",
        "\tper_device_train_batch_size=8, \n",
        "\tper_device_eval_batch_size=8,\n",
        "\tweight_decay=0.01,\n",
        "\t# learning_rate = 2e-5,#, #defaults to 5e-5\n",
        "\tlearning_rate = 5e-6,\n",
        "\tload_best_model_at_end = True,\n",
        "\t# lr_scheduler_type = \"cosine\"\n",
        "\t# report_to=\"wandb\"\n",
        "\t)\n",
        "\n",
        "trainer1 = Trainer(\n",
        "\t\tmodel=modelCBTNE,\n",
        "\t\targs=training_args,\n",
        "\t\ttrain_dataset=tokenized_datasetCBTNE_train[\"train\"],\n",
        "    eval_dataset=tokenized_datasetCBTNE_train[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "\t\tcompute_metrics=compute_metrics\n",
        ")\n",
        "trainer1.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602,
          "referenced_widgets": [
            "62cb3671ae214406ade4173dd31aacd0",
            "531d627adca946c2aa29498e593c180b",
            "9728877773b64e21959d94d1ac9d85a8",
            "acb84b6dc12342ca806e8809ad097637",
            "98c0c53ca1ce4dc38e5f802433421bb2",
            "ebbf6ff39f36460db140bced9a18d357",
            "9593cede277548d5b9e51ef022c116bf",
            "8fa4d698cd4d4aadb15bd9b87b197aae",
            "aedc87bef7b0430fbd1d699eabfd5b74",
            "98e1e218414a4d86bf36a1f6b46e6c36",
            "8c84fa396de9477385b04e8c3eb03a61"
          ]
        },
        "id": "PlH09pV9GfVy",
        "outputId": "a2274275-22d0-47be-aca7-9771dfeebbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62cb3671ae214406ade4173dd31aacd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                 \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-435c231ea9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrainer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"label\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2512\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2514\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2516\u001b[0m     def create_token_type_ids_from_sequences(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    609\u001b[0m                     )\n\u001b[1;32m    610\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 611\u001b[0;31m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m                     \u001b[0;34m\"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                 )\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasetCBTNE_test = datasetCBTNE_test.map(tokenize_function, batched=True)\n",
        "\n",
        "prediction1 = trainer1.predict(tokenized_datasetCBTNE_test)\n",
        "print(prediction1)"
      ],
      "metadata": {
        "id": "yuw4D6NfKmjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le8-CiDoLTMP",
        "outputId": "ba3229d5-5ed9-42f8-c5e3-5fb4a4a9f4f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['sentences', 'question', 'answer', 'options'],\n",
            "    num_rows: 108719\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "tokenizer1 = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=False)\n",
        "\n",
        "#Made another tokenizer function in hopes that it might change something, it did not\n",
        "def tokenize_function_qa(examples):\n",
        "    text = []\n",
        "    text.append(datasetCBTNE_train[\"sentences\"])\n",
        "    text.append('[SEP]')\n",
        "    text.append(datasetCBTNE_train[\"question\"])\n",
        "    # questions = datasetCBTNE_train[\"question\"]\n",
        "    # # questions = ','.join(map(str, questions))\n",
        "    # sentences = [q for q in datasetCBTNE_train[\"sentences\"] if q is not None]\n",
        "    # # options = [q for q in datasetCBTNE_train[\"options\"] if q is not None]\n",
        "    # # sentences = ','.join(map(str, sentences))\n",
        "    inputs = tokenizer1(text,\n",
        "        truncation=True,\n",
        "        # stride=128,\n",
        "        # return_overflowing_tokens=True,\n",
        "        # return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    return inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691,
          "referenced_widgets": [
            "4e6e03fbfcde4bde998d4ab9c4a05c60",
            "c78b5998cccb45e791e342356f7b9dfd",
            "5d821136d2514ad5a491681bad7b8f0a",
            "9c744af158f74e4480dffbc3e131f48a",
            "5aca9a41d3154a0fa35c38a35ae4689d",
            "942165d7bce54111a8088bce91b3d438",
            "1a72556f3a2c424dbc9122f1daded0ef",
            "e0f15393a7ee44a9b3aeb2babffd8c62",
            "e8cf58b20a594321ad41c0d54792967f",
            "fa9564bfaa3c4dde906e5f0fed2e0799",
            "bfb386b9ed694b81919f582aa365c144"
          ]
        },
        "id": "F-IKG0NREgi2",
        "outputId": "1d5d12a5-ad30-4e9e-ed6b-9a390c69d9f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e6e03fbfcde4bde998d4ab9c4a05c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b81f869e5464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistilBertForQuestionAnswering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodelCBT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenized_datasetCBTNE_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetCBTNE_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function_qa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtokenized_datasetCBTCN_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetCBTCN_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function_qa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasetCBTCN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m                 \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m             )\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         }\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2970\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m                                 \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2972\u001b[0;31m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2973\u001b[0m                             )\n\u001b[1;32m   2974\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m                 )\n\u001b[1;32m   2531\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4854b2e82754>\u001b[0m in \u001b[0;36mtokenize_function_qa\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# return_overflowing_tokens=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# return_offsets_mapping=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2488\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2546\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2547\u001b[0;31m                 \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2548\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2549\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForQuestionAnswering\n",
        "modelCBT = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = 10)\n",
        "tokenized_datasetCBTNE_train = datasetCBTNE_train.map(tokenize_function_qa, batched=True)\n",
        "tokenized_datasetCBTCN_train = datasetCBTCN_train.map(tokenize_function_qa, batched=True)\n",
        "print(tokenized_datasetCBTCN_train)\n",
        "print(tokenized_datasetCBTNE_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXynn_BSgEUQ"
      },
      "outputs": [],
      "source": [
        "#Tried to keep data in memory and read it from memory instead of loading it from huggingface as I saw this method online\n",
        "#Absolutely terrible method, the dataset is very big and Colab's RAM, even with Pro, is not anywhere near enough\n",
        "\n",
        "# !wget -N http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\n",
        "# !tar xf CBTest.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOOPM4CF5geX",
        "outputId": "9822868b-985a-40e8-94be-4cd7d812ead7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cache_dir\t\t    cbtest_P_train.txt\n",
            "CBTest\t\t\t    cbtest_P_valid_2000ex.txt\n",
            "cbtest_CN_test_2500ex.txt   CBTest.tgz\n",
            "cbtest_CN_train.txt\t    cbtest_V_test_2500ex.txt\n",
            "cbtest_CN_valid_2000ex.txt  cbtest_V_train.txt\n",
            "cbtest_NE_test_2500ex.txt   cbtest_V_valid_2000ex.txt\n",
            "cbtest_NE_train.txt\t    cbt_test.txt\n",
            "cbtest_NE_valid_2000ex.txt  cbt_train.txt\n",
            "cbtest_P_test_2500ex.txt    cbt_valid.txt\n"
          ]
        }
      ],
      "source": [
        "# # %cd CBTest\n",
        "# # %cd data\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So I believed that if I changed my input to the transformer model so that it contains only the labels and text (concatinating everything except the correct answer), it should work. I tried to do so but I was stuck in the cycle of fixing an error and then getting another error so on and so forth. "
      ],
      "metadata": {
        "id": "awFMxb9XWbhp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOVkxsRrgLjM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pickle\n",
        "#I gave up when using pickle for serializing and deserializing did not solve my issues and gave me more errors\n",
        "\n",
        "#Function to pre-process the data which was mounted from my google drive/read from memory\n",
        "\n",
        "def read_cbt_data(path, limit=None):\n",
        "    with open(path, 'r') as f:\n",
        "        stories = []\n",
        "        context = []\n",
        "        temp = []\n",
        "        lab = []\n",
        "        for line in f:\n",
        "            line = line.replace('\\n', '')\n",
        "            if line == '':\n",
        "                continue\n",
        "            m = re.match(r'[0-9]* ', line).end()\n",
        "            line_no = int(line[:m-1])\n",
        "            sentence = line[m:]\n",
        "            if line_no == 21: # process query.\n",
        "                sentence = sentence.split('\\t')\n",
        "                query = sentence[0].strip().split(' ')\n",
        "                answer = sentence[1].strip()\n",
        "                candidate = sentence[3].strip().split('|')\n",
        "                candidate = [c for c in candidate if c]\n",
        "                while len(candidate) < 10:\n",
        "                    candidate.append('<null>')\n",
        "                assert(len(candidate) == 10)\n",
        "                if context is not None:\n",
        "                  temp.append(context)\n",
        "                  temp.append('[SEP]')\n",
        "                if query is not None:\n",
        "                  temp.append(query)\n",
        "                  temp.append('[SEP]')\n",
        "                if answer is not None:\n",
        "                  lab.append(answer)\n",
        "                # story = dict()\n",
        "                # story['context'] = list(str(context))\n",
        "                # story['query'] = list(str(query))\n",
        "                # story['candidate'] = list(str(candidate))\n",
        "                # story['text'] = list(temp)\n",
        "                # story['labels'] = list(answer)\n",
        "                # story = {\n",
        "                #     'context': context,\n",
        "                #     'query': query,\n",
        "                #     'labels': answer,\n",
        "                #     'candidate': candidate\n",
        "                #     # 'labels': lab,\n",
        "                #     # 'text': text\n",
        "                # }\n",
        "                assert(len(context) == 20)\n",
        "                # stories.append(story)\n",
        "                if limit and len(stories) > limit:\n",
        "                    break\n",
        "                context = []\n",
        "                temp = []\n",
        "                lab = []\n",
        "            else:\n",
        "                context.append(sentence.strip().split(' '))\n",
        "        stories\n",
        "        stories = pd.DataFrame.from_dict(stories)\n",
        "        stories.to_pickle(\"/tmp/stories.pickle\")\n",
        "        with open(\"/tmp/stories.pickle\", \"rb\") as fin:\n",
        "            stories1 = pickle.load(fin)\n",
        "        return Dataset.from_pandas(stories1)\n",
        "        # return stories1\n",
        "        # return stories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI_H16vlkGUM",
        "outputId": "9f82f40c-13b3-40dc-9b8f-364e942a5c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "CBTCN_train_path = \"/content/drive/My Drive/data/cbtest_CN_train.txt\"\n",
        "CBTCN_validate_path = \"/content/drive/My Drive/data/cbtest_CN_valid_2000ex.txt\"\n",
        "CBTCN_test_path = \"/content/drive/My Drive/data/cbtest_CN_test_2500ex.txt\"\n",
        "\n",
        "CBTNE_train_path = \"/content/drive/My Drive/data/cbtest_NE_train.txt\"\n",
        "CBTNE_validate_path = \"/content/drive/My Drive/data/cbtest_NE_valid_2000ex.txt\"\n",
        "CBTNE_test_path = \"/content/drive/My Drive/data/cbtest_NE_test_2500ex.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-LxiP2A-5bq"
      },
      "outputs": [],
      "source": [
        "datasetCBT_CN_train = read_cbt_data(CBTCN_train_path)\n",
        "datasetCBT_CN_validate = read_cbt_data(CBTCN_validate_path)\n",
        "datasetCBT_CN_test = read_cbt_data(CBTCN_test_path)\n",
        "\n",
        "# datasetCBT_NE_train = read_cbt_data(\"cbtest_NE_train.txt\")\n",
        "# datasetCBT_NE_validate = read_cbt_data(\"cbtest_NE_valid_2000ex.txt\")\n",
        "# datasetCBT_NE_test = read_cbt_data(\"cbtest_NE_test_2500ex.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOZ5ndBwhC04"
      },
      "outputs": [],
      "source": [
        "#I was not able to apply the map function for some reason (to get my tokenized dataset through the tokenizer function)\n",
        "#And stackoverflow said that that function is for series as opposed to dataframes\n",
        "# I tried converting pandas dataframe to series so that I could use the map function on it but it did not work\n",
        "\n",
        "# print(datasetCBT_CN_test[:1])\n",
        "# print(datasetCBT_CN_train.stack())\n",
        "my_series1 = datasetCBT_CN_train['text'].squeeze()\n",
        "my_series2 = datasetCBT_CN_train['labels'].squeeze()\n",
        "my_series3 = my_series2.append(my_series1)\n",
        "print(my_series3)\n",
        "# datasetCBT_CN_train1 = Dataset.from_pandas(datasetCBT_CN_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Z6gP9-o0f-",
        "outputId": "5dd981b6-a9d9-453c-adbc-4845246fe67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tokenizer...\n"
          ]
        }
      ],
      "source": [
        "print(\"building tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# def tokenize_function(examples):\n",
        "# \t# print(type(examples[\"context\"]), type(examples[\"query\"]), type(examples[\"candidate\"]))\n",
        "# \ttoken = tokenizer(examples[\"context\"], examples[\"query\"], examples[\"candidate\"], padding=\"max_length\", truncation=True)\n",
        "# \treturn token\n",
        "def tokenize_function(examples):\n",
        "\tprint(examples[\"text\"])\n",
        "\ttoken = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\treturn token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600,
          "referenced_widgets": [
            "5617993de3c449b7b4a21e412387fc4d",
            "d0ba5024a1ca4c889bb218ee0afc344d",
            "b9aeda0cd5da46a5b717ad53a1b01068",
            "b9a7750194e24e1ea8cfdbbf6e22540a",
            "1ae9338c9d814edc8e039d8874f725ba",
            "f333ceb0701c477f9463ea5387a2b999",
            "27bb0f3bda1b4e3fa2b936937c905611",
            "f2a29d4a6b344ba48af1240e39e2ccd4",
            "c744cf73132b4284916ff5d17c9643fd",
            "df373e102b6a41149e43e14c9402ba5a",
            "6b08d5d32df846dc81cc1f28cf7ac780"
          ]
        },
        "id": "bpKMPTvdsaYU",
        "outputId": "435fbb6f-073c-44ff-adfc-a4de25d25653"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/121 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5617993de3c449b7b4a21e412387fc4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7cb9ef99838e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_datasetCBT_CN_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetCBT_CN_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasetCBT_CN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2588\u001b[0m                 \u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_fingerprint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m                 \u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m                 \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2591\u001b[0m             )\n\u001b[1;32m   2592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         }\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2970\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m                                 \u001b[0mcheck_same_num_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2972\u001b[0;31m                                 \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2973\u001b[0m                             )\n\u001b[1;32m   2974\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mNumExamplesMismatchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2852\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2853\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdate_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m                 \u001b[0;31m# Check if the function returns updated examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m                 )\n\u001b[1;32m   2531\u001b[0m                 \u001b[0;31m# Use the LazyDict internally, while mapping the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorated_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m                 \u001b[0;31m# Return a standard dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e7f32c70825d>\u001b[0m in \u001b[0;36mtokenize_function\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2136\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2138\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2139\u001b[0m             )\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2321\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2323\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2324\u001b[0m         )\n\u001b[1;32m   2325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "tokenized_datasetCBT_CN_train = datasetCBT_CN_train.map(tokenize_function, batched=True)\n",
        "print(tokenized_datasetCBT_CN_train)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "bS0_J6Vc4dKN",
        "outputId": "5338f344-b649-4a26-a717-3f8476285ae8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3bb9f846fcd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetCBT_CN_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasetCBT_CN_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Evaluate the model. (Being lazy and evaluating on the train data itself)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/question_answering/question_answering_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mtrain_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/question_answering/question_answering_model.py\u001b[0m in \u001b[0;36mload_and_cache_examples\u001b[0;34m(self, examples, evaluate, no_cache, output_examples)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dev\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/simpletransformers/question_answering/question_answering_utils.py\u001b[0m in \u001b[0;36mget_examples\u001b[0;34m(examples_to_process, is_training, version_2_with_negative)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples_to_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mcontext_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mqa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qas\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mqas_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mquestion_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'qas'"
          ]
        }
      ],
      "source": [
        "#I also tried to use simpletransformers but realized quickly that I do not understand enough about \n",
        "#this architecture and I did not have the time to familiarize myself with it\n",
        "\n",
        "# !pip install simpletransformers\n",
        "# import logging\n",
        "# from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n",
        "\n",
        "# # tokenized_datasetCBT_train = datasetCBT.map(tokenize_function, batched=True)\n",
        "# transformers_logger = logging.getLogger(\"transformers\")\n",
        "# transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# # Configure the model\n",
        "# model_args = QuestionAnsweringArgs()\n",
        "# model_args.train_batch_size = 8\n",
        "# model_args.evaluate_during_training = True\n",
        "\n",
        "# # Create the QuestionAnsweringModel\n",
        "# model = QuestionAnsweringModel(\n",
        "#     \"distilbert\", \"distilbert-base-uncased\",\n",
        "#     args=model_args\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# model.train_model(datasetCBT_CN_train, eval_data=datasetCBT_CN_validate)\n",
        "\n",
        "# # Evaluate the model. (Being lazy and evaluating on the train data itself)\n",
        "# result, text = model.eval_model(datasetCBT_CN_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a72556f3a2c424dbc9122f1daded0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e6e03fbfcde4bde998d4ab9c4a05c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c78b5998cccb45e791e342356f7b9dfd",
              "IPY_MODEL_5d821136d2514ad5a491681bad7b8f0a",
              "IPY_MODEL_9c744af158f74e4480dffbc3e131f48a"
            ],
            "layout": "IPY_MODEL_5aca9a41d3154a0fa35c38a35ae4689d"
          }
        },
        "5aca9a41d3154a0fa35c38a35ae4689d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d821136d2514ad5a491681bad7b8f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f15393a7ee44a9b3aeb2babffd8c62",
            "max": 109,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8cf58b20a594321ad41c0d54792967f",
            "value": 0
          }
        },
        "942165d7bce54111a8088bce91b3d438": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c744af158f74e4480dffbc3e131f48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9564bfaa3c4dde906e5f0fed2e0799",
            "placeholder": "​",
            "style": "IPY_MODEL_bfb386b9ed694b81919f582aa365c144",
            "value": " 0/109 [00:05&lt;?, ?ba/s]"
          }
        },
        "bfb386b9ed694b81919f582aa365c144": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78b5998cccb45e791e342356f7b9dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942165d7bce54111a8088bce91b3d438",
            "placeholder": "​",
            "style": "IPY_MODEL_1a72556f3a2c424dbc9122f1daded0ef",
            "value": "  0%"
          }
        },
        "e0f15393a7ee44a9b3aeb2babffd8c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8cf58b20a594321ad41c0d54792967f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa9564bfaa3c4dde906e5f0fed2e0799": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa84aab6c3b4dce86c3a7fcb428b9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12516509555e4681998ee83f6ee5811f",
              "IPY_MODEL_036b85d1eb954a5a9c430eb5a9a0013a",
              "IPY_MODEL_f35f7691a3ac4216bdbe4a6260878ed8"
            ],
            "layout": "IPY_MODEL_96255bd4ae914808ac5dbac9baf28c09"
          }
        },
        "12516509555e4681998ee83f6ee5811f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a111a92757414b2ca5d3c4f4a557b8d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e667576be66e44cca4261b78cd26ab6d",
            "value": "Downloading builder script: 100%"
          }
        },
        "036b85d1eb954a5a9c430eb5a9a0013a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393ab475c9f64be4ad49ec3614163277",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af7565d842b4680ab1d68ad381faed0",
            "value": 4203
          }
        },
        "f35f7691a3ac4216bdbe4a6260878ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ee0b822dfb4bd09708c65714678140",
            "placeholder": "​",
            "style": "IPY_MODEL_88503b6036d040bf93c617f9aafc1105",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 96.6kB/s]"
          }
        },
        "96255bd4ae914808ac5dbac9baf28c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a111a92757414b2ca5d3c4f4a557b8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e667576be66e44cca4261b78cd26ab6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393ab475c9f64be4ad49ec3614163277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af7565d842b4680ab1d68ad381faed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4ee0b822dfb4bd09708c65714678140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88503b6036d040bf93c617f9aafc1105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e5faec1a0eb4a81a26e8216e831083a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3e1cba538a04028a13e87d8e4f59f05",
              "IPY_MODEL_74b8a34fc19c450b83fd0f04bab8deee",
              "IPY_MODEL_797c34fd501a4a83ab0d75c9b048a57e"
            ],
            "layout": "IPY_MODEL_f78e5f226b854014902f6d2dbadcb42d"
          }
        },
        "e3e1cba538a04028a13e87d8e4f59f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e2454a032f4fe184f389c4f2526bff",
            "placeholder": "​",
            "style": "IPY_MODEL_05c244827e8f444593874fd546e03fef",
            "value": " 99%"
          }
        },
        "74b8a34fc19c450b83fd0f04bab8deee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b04a0208011402bae3d2ec18a6e9103",
            "max": 93,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9118d819f12142a18474e85b95af5cdd",
            "value": 92
          }
        },
        "797c34fd501a4a83ab0d75c9b048a57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78fedc7cde04996a8031f499ad4487c",
            "placeholder": "​",
            "style": "IPY_MODEL_ae465cc8523c44a783ac4759e1213c38",
            "value": " 92/93 [01:20&lt;00:00,  1.08ba/s]"
          }
        },
        "f78e5f226b854014902f6d2dbadcb42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e2454a032f4fe184f389c4f2526bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c244827e8f444593874fd546e03fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b04a0208011402bae3d2ec18a6e9103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9118d819f12142a18474e85b95af5cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a78fedc7cde04996a8031f499ad4487c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae465cc8523c44a783ac4759e1213c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd88d466f7644bf89f40cde073e1d449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a94fea8dd6948a4928df564620c2e93",
              "IPY_MODEL_62345609f82749c387d2ccf0d87116ea",
              "IPY_MODEL_75e5a11489eb448c9e93f8d9fd25ba57"
            ],
            "layout": "IPY_MODEL_d2af333e809d49a89cbeb33253d8ea6f"
          }
        },
        "7a94fea8dd6948a4928df564620c2e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f45818e6574246b8151af26cb31a8f",
            "placeholder": "​",
            "style": "IPY_MODEL_d3c4ee213fce482c906ebd08b216e20a",
            "value": " 94%"
          }
        },
        "62345609f82749c387d2ccf0d87116ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7aac9711f214ff4be198b60b2e0ed26",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5df93393edff4e6097ddb09c9f0b8e74",
            "value": 16
          }
        },
        "75e5a11489eb448c9e93f8d9fd25ba57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284dffbf9b6142be8d12de51fae83ff9",
            "placeholder": "​",
            "style": "IPY_MODEL_e3dc5acfa0d24a3e8f723534ac56b159",
            "value": " 16/17 [00:14&lt;00:00,  1.13ba/s]"
          }
        },
        "d2af333e809d49a89cbeb33253d8ea6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f45818e6574246b8151af26cb31a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c4ee213fce482c906ebd08b216e20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7aac9711f214ff4be198b60b2e0ed26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df93393edff4e6097ddb09c9f0b8e74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "284dffbf9b6142be8d12de51fae83ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3dc5acfa0d24a3e8f723534ac56b159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62cb3671ae214406ade4173dd31aacd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_531d627adca946c2aa29498e593c180b",
              "IPY_MODEL_9728877773b64e21959d94d1ac9d85a8",
              "IPY_MODEL_acb84b6dc12342ca806e8809ad097637"
            ],
            "layout": "IPY_MODEL_98c0c53ca1ce4dc38e5f802433421bb2"
          }
        },
        "531d627adca946c2aa29498e593c180b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebbf6ff39f36460db140bced9a18d357",
            "placeholder": "​",
            "style": "IPY_MODEL_9593cede277548d5b9e51ef022c116bf",
            "value": "Downloading: 100%"
          }
        },
        "9728877773b64e21959d94d1ac9d85a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa4d698cd4d4aadb15bd9b87b197aae",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aedc87bef7b0430fbd1d699eabfd5b74",
            "value": 267967963
          }
        },
        "acb84b6dc12342ca806e8809ad097637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e1e218414a4d86bf36a1f6b46e6c36",
            "placeholder": "​",
            "style": "IPY_MODEL_8c84fa396de9477385b04e8c3eb03a61",
            "value": " 268M/268M [00:14&lt;00:00, 19.9MB/s]"
          }
        },
        "98c0c53ca1ce4dc38e5f802433421bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebbf6ff39f36460db140bced9a18d357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9593cede277548d5b9e51ef022c116bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fa4d698cd4d4aadb15bd9b87b197aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aedc87bef7b0430fbd1d699eabfd5b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98e1e218414a4d86bf36a1f6b46e6c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c84fa396de9477385b04e8c3eb03a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5617993de3c449b7b4a21e412387fc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0ba5024a1ca4c889bb218ee0afc344d",
              "IPY_MODEL_b9aeda0cd5da46a5b717ad53a1b01068",
              "IPY_MODEL_b9a7750194e24e1ea8cfdbbf6e22540a"
            ],
            "layout": "IPY_MODEL_1ae9338c9d814edc8e039d8874f725ba"
          }
        },
        "d0ba5024a1ca4c889bb218ee0afc344d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f333ceb0701c477f9463ea5387a2b999",
            "placeholder": "​",
            "style": "IPY_MODEL_27bb0f3bda1b4e3fa2b936937c905611",
            "value": "  0%"
          }
        },
        "b9aeda0cd5da46a5b717ad53a1b01068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a29d4a6b344ba48af1240e39e2ccd4",
            "max": 121,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c744cf73132b4284916ff5d17c9643fd",
            "value": 0
          }
        },
        "b9a7750194e24e1ea8cfdbbf6e22540a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df373e102b6a41149e43e14c9402ba5a",
            "placeholder": "​",
            "style": "IPY_MODEL_6b08d5d32df846dc81cc1f28cf7ac780",
            "value": " 0/121 [00:02&lt;?, ?ba/s]"
          }
        },
        "1ae9338c9d814edc8e039d8874f725ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f333ceb0701c477f9463ea5387a2b999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bb0f3bda1b4e3fa2b936937c905611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2a29d4a6b344ba48af1240e39e2ccd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c744cf73132b4284916ff5d17c9643fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df373e102b6a41149e43e14c9402ba5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b08d5d32df846dc81cc1f28cf7ac780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}